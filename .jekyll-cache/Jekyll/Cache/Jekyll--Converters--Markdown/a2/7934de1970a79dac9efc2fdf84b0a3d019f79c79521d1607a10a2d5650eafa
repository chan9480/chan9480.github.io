I"?<h2 id="유명-이미지-데이터">유명 이미지 데이터</h2>
<p>cifar10, 100 : 클래스 10, 100개의 갖는 사물 이미지(32,32) 데이터 셋 (학습용 50000개)<br />
imagenet :  클래스 훨씬 다양(몇천, 몇만), 백만개가 넘음.<br />
MS COCO : 객체탐지를 목적으로 하는 이미지셋, 클래스와 위치(bbox)등의 정보가 함께있다. 15만장 이상 (train, val, test 포함)</p>

<h2 id="객체-인식-모델의-전반적인-생김새">객체 인식 모델의 전반적인 생김새</h2>
<p><img src="/assets/images/source_34.png" height="100%" />
&lt; 2stage와 1stage 구조 그림&gt;</p>

<ol>
  <li>
    <p>2-stage detector : region proposal network를 포함한다. 이는 자주 탐지되는 부분을 학습한다는 의미. + localization과 classification을 ‘각각’ 진행한다는 의미.</p>
  </li>
  <li>
    <p>single(1-stage) detector : localization과 classification을 동시에 진행.</p>
  </li>
</ol>

<h2 id="객체-분류-backbone">객체 분류 (Backbone)</h2>
<ul>
  <li>
    <p>VGGnet : 3x3 conv만 사용하여 구조가 단순한데 비해 기능은 준수함.</p>
  </li>
  <li>
    <p>Resnet : 3x3 conv를 포함하며 conv를 무시 후 지나가는 shortcut을 갖는 residual block 으로 구성됨. (Resnet152에서는 1x1 conv를 포함하는 residual block을 사용함) 기울기 손실 방지를 통해 깊이를 깊게 쌓을 수 있게 됨.</p>
  </li>
  <li>
    <p>Dense net : Resnet같이 relu가 아닌, concat으로 이전 정보를 가져간다는 차이가 있음.<br />
<img src="/assets/images/source_35.png" width="50%" /></p>
  </li>
  <li>CSP-Darknet : Densenet을 기초로 CSP를 적용시킴 <br />
<img src="/assets/images/source_36.png" height="100%" /></li>
  <li>CSP : 분리된 feature map을 다시 병합해주다?</li>
</ul>

<h2 id="neck">Neck</h2>
<ul>
  <li>
    <p>additional blocks : 다양한 크기의 피쳐맵들을 만들어 정보를 수집<br />
(사진 예시(상) : SPP, 모든 피쳐맵들을 몇가지 경우의 grid로 나누어 flatten한 후 평균을 냄 )<br />
<img src="/assets/images/source_38.png" width="50%" /></p>
  </li>
  <li>
    <p>path-aggregation blocks : bottom-up path 와 top-down path에서 정보를 수집<br />
(사진 예시(하) : PAN, 기존 FPN 네트워크에서 빨간선, 초록선과 같이 low-level-feature를 high-level-feature에 전달하여 성능을 향상시킴.) <br />
<img src="/assets/images/source_39.png" height="70%" /></p>
  </li>
</ul>

<h2 id="head">Head</h2>
<p>1-stage, 2stage 외에도 anchor free인지, anchor-based인지로 나뉠 수 있다.(2x2총 4개 종)<br />
anchor의 크기를 고정, 지정하는 방식이 anchor-based, anchor-free는 앵커의 크기를 지정할 필요가 없다.<br />
따라서 anchor-based방식은 앵커의 크기, 종횡비를 파라미터로 필요로 하며, 정확도에 민감하게 영향을 끼치고,<br />
그만큼 메모리와 학습 및 테스트 시간이 더 소요된다.</p>

<p><img src="/assets/images/source_40.png" width="20%" /></p>

<ol>
  <li>faster R-CNN (2-stage, anchor-based에 해당)<br />
자주 생성되는 위치를 학습한다. region proposal net</li>
  <li>사이즈 제한 YOLO (1-stage, anchor-based에 해당)
정해진 그리드로 나누어 CNN으로 처리한다.</li>
</ol>

<p>미완, 참고중 :<br />
https://herbwood.tistory.com/24<br />
https://deep-learning-study.tistory.com/528<br />
https://ganghee-lee.tistory.com/34</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>
:ET