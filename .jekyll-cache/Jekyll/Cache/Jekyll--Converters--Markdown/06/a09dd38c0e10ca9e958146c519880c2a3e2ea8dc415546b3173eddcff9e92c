I"	<h2 id="사이킷런sklearn-파이프라인-pipeline">사이킷런(sklearn) 파이프라인 (PipeLine)</h2>
<p>사이킷런에서 제공하는 파이프라인은 각 기능을 하는 모델들을 한번에 묶는 기능과<br />
하이퍼 파라미터를 연결시키는 기능이 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.pipeline import make_pipeline
from category_encoders import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier

pipe = make_pipeline(
    OneHotEncoder(use_cat_names=True),  
    SimpleImputer(),
    StandardScaler(),
    DecisionTreeClassifier(random_state=1, criterion='entropy')
)

# pipe fit
pipe.fit(x_train, y_train)
print('검증세트 정확도', pipe.score(X_val, y_val))

# 테스트 셋
y_pred = pipe.predict(X_test)
</code></pre></div></div>

<h2 id="결정트리-decision_tree">결정트리 (Decision_Tree)</h2>
<p>결정트리는 ‘분류’에 있어서 마치 ‘회귀’의 선형회귀 와 같은 느낌이다.<br />
데이터들을 계속해서 두가지씩 분류하여 결과적으로</p>

<p><img src="/assets/images/source_21.png" width="60%" height="60%" title="제목" alt="아무거나" />
결정트리를 발전시킨<br />
‘랜덤포레스트 (Random_Forest)’,<br />
‘그래디언트 부스트 트리 (Gradient Boosted Tree)’<br />
같은 모델들을 더 많이 사용할 것이다.<br />
그러나 그 기초는 결정트리에 있다.</p>

<blockquote>
  <p>트리학습에서의 비용함수</p>
</blockquote>

<ol>
  <li>지니지수 (Gini Impurity</li>
  <li>엔트로피 (Entropy)</li>
</ol>

<p>두가지 모두 불순도를 나타내는 척도 이며<br />
클수록 골고루 섞여 있다는 뜻.(10개의 공들 중에 5개씩 빨간공, 파란공이라면 0.5)
즉, 0에 가까울수록 치우쳐져 있다는 뜻. (전부 특정공만 10개 있다면 0)</p>

<p>즉 지니지수, 엔트로피가 작아지는 방향으로 트리 노드를 생성한다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>
:ET