I"<h2 id="유명-이미지-데이터">유명 이미지 데이터</h2>
<p>cifar10, 100 : 클래스 10, 100개의 갖는 사물 이미지(32,32) 데이터 셋 (학습용 50000개)<br />
imagenet :  클래스 훨씬 다양(몇천, 몇만), 백만개가 넘음.<br />
MS COCO : 객체탐지를 목적으로 하는 이미지셋, 클래스와 위치(bbox)등의 정보가 함께있다. 15만장 이상 (train, val, test 포함)</p>

<h2 id="객체-인식-모델의-전반적인-생김새">객체 인식 모델의 전반적인 생김새</h2>
<p><img src="/assets/images/source_34.png" height="100%" />
&lt; 2stage와 1stage 구조 그림&gt;</p>

<ol>
  <li>
    <p>2-stage detector : region proposal network를 포함한다. 이는 자주 탐지되는 부분을 학습한다는 의미. + localization과 classification을 ‘각각’ 진행한다는 의미.</p>
  </li>
  <li>
    <p>single(1-stage) detector : localization과 classification을 동시에 진행.</p>
  </li>
</ol>

<h2 id="객체-분류-backbone">객체 분류 (Backbone)</h2>
<ul>
  <li>
    <p>VGGnet : 3x3 conv만 사용하여 구조가 단순한데 비해 기능은 준수함.</p>
  </li>
  <li>
    <p>Resnet : 3x3 conv를 포함하며 conv를 무시 후 지나가는 shortcut을 갖는 residual block 으로 구성됨. (Resnet152에서는 1x1 conv를 포함하는 residual block을 사용함) 기울기 손실 방지를 통해 깊이를 깊게 쌓을 수 있게 됨.</p>
  </li>
  <li>
    <p>Dense net : Resnet같이 relu가 아닌, concat으로 이전 정보를 가져간다는 차이가 있음.<br />
기울기 소실을 무시하는 수준, 모든 레이어가 연산없이 이어져 붙여버림을 의미.<br />
단, 계속 이어붙이면 채널이 늘어나니까, 각 레이어에서 사용하는 채널은 상대적으로 적게 사용하므로써,<br />
연산량이 줄어든다. (결과에 의한 효과라기보단 채널을 줄였으니 당연한것.)
<img src="/assets/images/source_35.png" width="50%" /></p>
  </li>
  <li>CSP-Darknet : Densenet을 기초로 CSP를 적용시킴 <br />
<img src="/assets/images/source_36.png" height="100%" /></li>
  <li>CSP : 분리된 feature map을 다시 병합해주다?</li>
</ul>

<h2 id="neck">Neck</h2>
<ul>
  <li>
    <p>additional blocks : 다양한 크기의 피쳐맵들을 만들어 정보를 수집<br />
(사진 예시 : SPP, 모든 피쳐맵들을 몇가지 경우의 grid로 나누어 풀링시킨 후 flatten)<br />
<img src="/assets/images/source_38.png" width="50%" /></p>
  </li>
  <li>
    <p>path-aggregation blocks : bottom-up path 와 top-down path에서 정보를 수집<br />
(사진 예시 : PAN, 기존 FPN 네트워크에서 빨간선, 초록선과 같이 low-level-feature를 high-level-feature에 전달하여 성능을 향상시킴.) <br />
<img src="/assets/images/source_39.png" height="70%" /></p>
  </li>
</ul>

<h2 id="head">Head</h2>
<p>1-stage, 2stage 외에도 anchor free인지, anchor-based인지로 나뉠 수 있다.(2x2총 4개 종)<br />
anchor의 크기를 고정, 지정하는 방식이 anchor-based, anchor-free는 앵커의 크기를 지정할 필요가 없다.<br />
따라서 anchor-based방식은 앵커의 크기, 종횡비를 파라미터로 필요로 하며, 이는 정확도에 민감하게 영향을 끼치고,<br />
그만큼 메모리와 학습 및 테스트 시간이 더 소요된다.</p>

<p><img src="/assets/images/source_40.png" width="50%" /></p>

<ol>
  <li>faster R-CNN (2-stage, anchor-based에 해당)<br />
자주 생성되는 위치를 학습한다. region proposal net</li>
  <li>
    <p>사이즈 제한 YOLO (1-stage, anchor-based에 해당)
정해진 그리드로 나누어 CNN으로 처리한다.</p>
  </li>
  <li>그외 RepPoints(2-stage, anchor-free), FCOS(1-stage, anchor-free) 등의 모델도 있다.</li>
</ol>

<h2 id="마무리">마무리</h2>
<p>제목을 수정했다.(전 제목 : YOLO 이해를 위한 … )<br />
이 포스팅을 작성하는 중에 여러 일정들이 생기면서 완성하는 데 까지 시간이 오래 걸렸는데,<br />
작성을 하다보니 ‘YOLO’모델을 이해하기 보다는<br />
이 모델이 CNN 기반 모델들 가운데 어떤 포지션에 위치하는 정도를<br />
파악하는 포스팅이 되어버린 듯한 느낌이 들었기 때문이다.</p>

<p>구덩이 하나를 파고들기 전에 그 구덩이가 어디쯤에 위치하고 있는지 파악하는 레벨이랄까..</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>
:ET