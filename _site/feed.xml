<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-03-21T15:22:53+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">배우자 그리고 써먹자</title><subtitle>포트폴리오</subtitle><author><name>옹달샘👱🏼‍♂️</name></author><entry><title type="html">CNN 구조 이해</title><link href="http://localhost:4000/ds/CNN/" rel="alternate" type="text/html" title="CNN 구조 이해" /><published>2022-03-19T00:00:00+09:00</published><updated>2020-03-19T00:00:00+09:00</updated><id>http://localhost:4000/ds/CNN</id><content type="html" xml:base="http://localhost:4000/ds/CNN/"><![CDATA[<h2 id="cnn-의-목적">CNN 의 목적</h2>
<p>컴퓨터에 이미지를 이해시키는 방법을 생각해보자.<br />
이미지는 RGB, BGR의 3자리 숫자가 모든 점들을 구성한다.<br />
그렇다면 강아지 사진 1의 모든 RGB 숫자들을 그대로 컴퓨터에게 알려준다면,<br />
컴퓨터는 구도만 살짝 바뀐 강아지 사진 2는 전혀 다른 사진이라고 생각할 것이다.</p>

<p>이를 위해 CNN에서는 ‘필터’라는 개념을 이용하여 ‘특징’을 추출한다.</p>

<h2 id="이것만-이해하자-no1">이것만 이해하자. No.1</h2>
<p><img src="/assets/images/ds/source_0.png" width="60%" height="60%" /><br />
필터는 위와같이 적용된다. 필터 하나하나가 가중치의 역할을 하며, 필터의 모양에 따라 이미지의 어떤 특징들을 추출하는지 결정된다.</p>

<h2 id="이것만-이해하자-no2">이것만 이해하자. No.2</h2>
<p><img src="/assets/images/ds/source_1.png" width="60%" height="60%" /><br />
—————————————————————————-<br />
CNN의 Layer를 하나씩 쌓고 있다.<br />
첫번째 Conv2D 코드를 보자,  (32,32) 사이즈의 3겹(rgb, bgr) 이미지를 3by3 필터 가중치를 이용하여 32개의 feature map을 만들겠다고 되어있다.<br />
그 결과, (30,30) 사이즈의 32겹 피쳐맵을 만들었고, param수는 896개이다.<br />
가중치의 갯수는 신경망의 원리에서 각 가중치를 필터로 갖는다고 생각하면 쉽다.<br />
3 (=input) x 32(=output) x 9(=3*3필터) + 32(퍼셉트론 신경망 node와 같이 각 feature맵 가중치)<br />
=895</p>

<h2 id="이것만-이해하자-no3">이것만 이해하자. No.3</h2>
<p><img src="/assets/images/ds/source_2.png" width="40%" height="40%" /><br />
No.2의 예시에서 (32,32)가 (30,30)으로 되는 건 3*3필터를 대입해보면 얼추 바로 알 수 있는데,<br />
stride나 padding이 들어가면 헷갈릴 수 있다. 위 식에 대입해서 정확히 구할 수 있다.</p>

<h2 id="키워드-정리">키워드 정리</h2>
<ol>
  <li>필터 (kernel, filter)</li>
  <li>피쳐맵 (feature map)</li>
  <li>패딩 (padding, zero padding) : 가장자리에서 필터때문에 소실되는 데이터를 막기 위해 사용, 이미지를 한번 0으로 감싸는 것.
    <ul>
      <li>사이즈에 따라 분류 : valid padding(패딩안함),<br />
 full padding (필터사이즈-1 만큼두께로 모두 감싸는 것, edge의 데이터 손실을 막는다는 의의를 가진다),<br />
 same padding(input이미지와 output이미지 사이즈가 같도록 패딩, 사이즈가 점점 작아지는 현상을 막는 다는 의미가 있음.)</li>
    </ul>
  </li>
  <li>스트라이드 (stride) : 커널을 대입할 때, 이동하는 칸 수를 말한다. (1이면 한칸씩 이동)</li>
</ol>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[CNN 의 목적 컴퓨터에 이미지를 이해시키는 방법을 생각해보자. 이미지는 RGB, BGR의 3자리 숫자가 모든 점들을 구성한다. 그렇다면 강아지 사진 1의 모든 RGB 숫자들을 그대로 컴퓨터에게 알려준다면, 컴퓨터는 구도만 살짝 바뀐 강아지 사진 2는 전혀 다른 사진이라고 생각할 것이다.]]></summary></entry><entry><title type="html">사람얼굴에 스타일 바꿔보기</title><link href="http://localhost:4000/pj/stylegan/" rel="alternate" type="text/html" title="사람얼굴에 스타일 바꿔보기" /><published>2022-03-10T00:00:00+09:00</published><updated>2022-03-13T00:00:00+09:00</updated><id>http://localhost:4000/pj/stylegan</id><content type="html" xml:base="http://localhost:4000/pj/stylegan/"><![CDATA[<h2 id="목표">목표</h2>
<p>임의의 초상권 없는 얼굴을 특정 스타일을 입혀 만들기.</p>

<h2 id="방법">방법</h2>
<p>임시로 생성한 사람얼굴(실존x) 이미지에 원하는 특정 스타일을 가진 사람(실존o)의 이미지를 적용하여 새롭게 생성.</p>

<ol>
  <li>styleGAN2-ada 모델의 ffhq preTrained 가중치를 사용하여 얼굴생성.</li>
  <li>원하는 스타일의 사람사진의 스타일 벡터들을 추출 (PSP 모델의 일부 사용)</li>
  <li>1번에서 생성한 이미지를 inversion하여 다시 이미지를 생성하는 과정에서 2번의 스타일 벡터들을 inject하여 최종 생성.</li>
</ol>

<p><img src="/assets/images/source_26.png" width="100%" height="60%" title="제목" alt="아무거나" /></p>

<h2 id="stylegan2---ada-간단-요약">StyleGAN2 - ada 간단 요약</h2>
<p>GAN (latent vector로 부터 이미지 생성) 모델 중에서<br />
styleGAN (latent vector를 style 별로 생성된 여러 w-vector로 만들어 이미지 생성) 이 있다.</p>

<p>ada는 데이터 증강기법(적은 데이터로 다양한 데이터생성, 일반화 효과 + 데이터 수 늘리는 효과)</p>

<h2 id="psppixel2style2pixel-간단-요약">PSP(pixel2style2pixel) 간단 요약</h2>
<p>구조를 두 부분으로 나눌 수 있는데,</p>
<ol>
  <li>psp encoder : 이미지를 매핑하여 w-vector를 생성함.</li>
  <li>styleGAN generator  : w-vector를 사용하여 이미지를 생성(styleGAN 방식과 같이 해상도를 올리면서 이미지 생성.)</li>
</ol>

<p>이 구조를 이용해서 여러 기능으로 사용가능 (ffhq_encode, celeb_seg_to_face, toonify 등)</p>

<h2 id="test-이미지">test 이미지</h2>
<p>styleGAN2-ada, ffhq-pretrained 로 생성한 이미지 들<br />
<img src="/assets/images/project/test_img0.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img10.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img19.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img4.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img12.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img16.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>

<h2 id="결과-이미지">결과 이미지</h2>
<blockquote>
  <p>스타일이미지</p>
</blockquote>

<p><img src="/assets/images/project/단발.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>
<blockquote>
  <p>결과 이미지<br />
순서대로 <strong>“스타일 적용전”</strong> ::::::: <strong>“w벡터 중 랜덤으로 1 개만 적용”</strong> ::::::: <strong>“모든 w벡터를 적용한 경우”</strong></p>
</blockquote>

<p><img src="/assets/images/project/test_img0.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/0/mask_some.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/0/mask_all.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>

<p><img src="/assets/images/project/test_img10.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/10/mask_some.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/10/mask_all.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>

<p><img src="/assets/images/project/test_img19.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/19/mask_some.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/19/mask_all.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>

<h2 id="결론">결론</h2>

<p>결과를 해석하자면</p>
<ol>
  <li>스타일이미지의 얼굴형, 머리스타일 등에 원본이미지의 눈코입, 피부 등을 적용시켜 이미지를 생성한다.</li>
  <li>랜덤한 w벡터를 적용했을 때, 스타일 이미지의 정확히 어떤 특징을 담은 w벡터가 적용된 것인지 알기 힘들다..<br />
(물론 스타일이미지와 무언가 닮아지긴 한다.)</li>
</ol>

<p>성공적인가의 여부는 스타일 이라는 애매한 단어에 어떤 걸 포함시키느냐에 따라 해석이 다를 것 같다.<br />
얼굴형, 머리스타일을 ‘스타일’이라고 한다면, 성공에 가깝다고 볼 수 있겠다!<br />
다만 원하는 스타일(머리스타일, 얼굴형 중 하나를 택하고 싶은 경우)을 적용하는데에는 실험적인 시도가 필요해 보인다.</p>

<h2 id="레포지토리-링크">레포지토리 링크</h2>
<p><a href="https://github.com/chan9480/Style_image_GAN">https://github.com/chan9480/Style_image_GAN</a></p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="pj" /><category term="styleGAN2" /><category term="PSP" /><summary type="html"><![CDATA[목표 임의의 초상권 없는 얼굴을 특정 스타일을 입혀 만들기.]]></summary></entry><entry><title type="html">데이터 인코딩(encoding)</title><link href="http://localhost:4000/ds/encoding/" rel="alternate" type="text/html" title="데이터 인코딩(encoding)" /><published>2022-03-06T00:00:00+09:00</published><updated>2022-03-06T00:00:00+09:00</updated><id>http://localhost:4000/ds/encoding</id><content type="html" xml:base="http://localhost:4000/ds/encoding/"><![CDATA[<h2 id="인코딩은-왜-하는거">인코딩은 왜 하는거?</h2>
<p>데이터에는 연속적인 숫자만 있는게 아니다.<br />
문자열의 카테고리형 feature일 수도,<br />
숫자라 하더라도 비연속적인 카테고리형 feature도 있다.<br />
(예: 사는지역(“수유동”, “인수동” …), 평점(“매우별로”,”별로”, … , “매우좋음”))</p>

<p>인코딩은 이러한 카테고리형 feature들에 대하여 ‘데이터’로써 유의미하도록 숫자로 바꿔주는 역할을 한다.</p>

<h2 id="인코딩의-종류와-간단-정리">인코딩의 종류와 간단 정리</h2>
<p>본래 데이터<br />
<img src="/assets/images/source_27.png" width="30%" height="60%" title="제목" alt="아무거나" /></p>

<ol>
  <li>One Hot Encoding<br />
하나의 feature가 갖는 범주 전체에 대하여 ‘이다’, ‘아니다’로 분류하여 0, 1을 갖는 feature를 생성.<br />
(사는지역의 종류가 “수유동”, “쌍문동” 등 16개의 동이 있다면, 16개의 feature (사는지역_수유동, 사는지역_쌍문동… 등)
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pd.get_dummies(df, prefix=["지  "], columns=["사는지역"])
#또는 아래처럼 sklern.preprocessing의 함수 사용
from sklearn.preprocessing import OneHotEncoder
</code></pre></div>    </div>
    <p><img src="/assets/images/source_28.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>
  </li>
  <li>Ordinal Encoding
categorical_feature의 값들이 어떤 <strong>‘순서’</strong>를 갖고있을 때 사용한다.<br />
(‘매우 그렇다’, ‘그렇다’, ‘보통’, ‘아니다’, ‘매우 아니다’) 같은거!
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.preprocessing import OrdinalEncoder
enc = OrdinalEncoder(categories = [['불만족', '보통', '만족']])
df['선호도_enc']=enc.fit_transform(df[['선호도']])
</code></pre></div>    </div>
    <p><img src="/assets/images/source_29.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>
  </li>
  <li>Binary Encoding
OneHotEncoding의 이진수 버전이라고 이해했다.<br />
사는지역의 종류가 16개의 동이 있다면. 4자리 이진수로 표현이 가능하므로 <strong>4개의 feature를 생성</strong> 한다.(cardinality가 너무 큰 특성에 대해서 사용하면 장점일 듯!)<br />
‘수유동은’ 4개의 feature에 0이나 1이 채워져 0000부터 1111중 하나의 형태를 가질 것!
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import category_encoders as ce
encoder = ce.BinaryEncoder(cols=['사는지역'])
dfbin = encoder.fit_transform(df['사는지역'])
df = pd.concat([df, dfbin], axis=1)
df.drop(['선호도','성별(1남, 0여)'], axis=1)
</code></pre></div>    </div>
    <p><img src="/assets/images/source_30.png" width="30%" height="60%" title="제목" alt="아무거나" /></p>
  </li>
  <li>Frequency Encoding
빈도로써 표현하는 방법<br />
‘수유동’이 10개 데이터중 2번있다면 0.2로 매핑됨.
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Frequency Encoding
fe = df.groupby("사는지역").size()/len(df)
df.loc[:, "사는지역_freq_encode"] = df["사는지역"].map(fe)
df
</code></pre></div>    </div>
    <p><img src="/assets/images/source_31.png" width="30%" height="60%" title="제목" alt="아무거나" /></p>
  </li>
  <li>
    <p>Mean Encoding<br />
여기부터는 지도학습에만 해당하는 내용이라고 생각한다. <strong>‘target’</strong> 이 존재할 때만 가능하기 때문!<br />
어떻게 인코딩을 시킬 지를 ‘타겟의 평균값’에 따라 결정한다.</p>

    <p>먼저, 단순하게 target의 평균자체로 매핑을 하는 방법이 있는데,<br />
(target을 gender라 하면, 수유동에사는 사람들의 target평균을 수유동의 인코딩 매핑값으로 삼는다.)<br />
과적합이 되기 쉽다.<br />
————————————————————————————–</p>

    <p>두번째로, smoothing mean target encoding은 과적합을 좀더 방지한다.<br />
(수유동 사람들의 target평균 / weight) + (전체 target평균 / 수유동의 갯수)<br />
 의미 : weight로 개별평균을 분산시켜주고, 수유동의 갯수가 클수록 수유동평균에 힘을, 수유동 갯수가 적다면 전체평균의 힘을 실어준다.<br />
weight가 클수록 편차가 작아진다!</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> # smoothing target encoding
 # 1. 평균을 계산
 mean = df['성별(1남, 0여)'].mean()
 # 2. 각 그룹에 대한 값들의 빈도와 평균을 계산
 Agg = df.groupby('사는지역')['성별(1남, 0여)'].agg(['count', 'mean'])
 counts = Agg['count']
 means = Agg['mean']
 weight = 10
 # 3. “smooth”한 평균을 계산
 smooth = (counts * means + weight * mean) / (counts + weight)
 # smooth한 평균에 따라 각 값을 대체하는 것
 print(smooth)
 df.loc[:, '사는지역_smean_enc'] = df['사는지역'].map(smooth)
 df
</code></pre></div>    </div>
    <p><img src="/assets/images/source_32.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>
  </li>
  <li>Probability Ratio Encoding (확률비율 인코딩)<br />
(target이 1인 확률 / target이 0인 확률) 의 비율로 매핑을 하는 방법이다.<br />
주의할 점은 0으로나뉘는걸 꼭 방지하자!  <br />
(예 : ‘수유동’들 중에 target이 1인갯수는 3개, 0인갯수는 1개라면, ‘수유동’은 3으로 매핑됨.)</li>
  <li>Weight of Evidence Encoding<br />
위 PRE의 비율에 log_2를 취하고 weight을 곱해준 것으로 인코딩하는 방법.<br />
(6번 인코딩 예시에서 ‘수유동’은 w*ln(3)의 값으로 매핑 될 것.)</li>
</ol>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[인코딩은 왜 하는거? 데이터에는 연속적인 숫자만 있는게 아니다. 문자열의 카테고리형 feature일 수도, 숫자라 하더라도 비연속적인 카테고리형 feature도 있다. (예: 사는지역(“수유동”, “인수동” …), 평점(“매우별로”,”별로”, … , “매우좋음”))]]></summary></entry><entry><title type="html">크롤링(Crawling)</title><link href="http://localhost:4000/de/crawling/" rel="alternate" type="text/html" title="크롤링(Crawling)" /><published>2022-03-05T00:00:00+09:00</published><updated>2022-03-05T00:00:00+09:00</updated><id>http://localhost:4000/de/crawling</id><content type="html" xml:base="http://localhost:4000/de/crawling/"><![CDATA[<h2 id="크롤링이란-">크롤링이란 ?</h2>
<p>web에 있는 데이터들을 긁어모으는 것을 말한다.<br />
크게 두 종류로 먼저 나눌 수 있다.</p>
<ol>
  <li>정적크롤링 : 항상 같은 값을 주는 HTML로 부터 파싱을 해서 크롤링.</li>
  <li>동적크롤링 : 같은 HTML이라도 동작, 명령을 통해 변화된 상태에서 데이터들을 크롤링.</li>
</ol>

<p>정적크롤링은 멈춰있는 페이지에서 정보를 찾아 긁어모은다면,<br />
동적크롤링은 검색, 스크롤, 페이지 클릭 등을 해서 나오는 정보를 긁어모을 수 있다.</p>

<p>대표적으로 정적크롤링 관련 라이브러리로 beautifulsoup(bs4)가 있다.<br />
그리고 동적크롤링의 방법에도 여러 종류가 있는데 그 중 2가지를 적어보자면 다음과 같다.</p>
<ol>
  <li>openAPI를 이용하여 명령 후, response된 정보로부터 크롤링.</li>
  <li>selenium을 통해 webdriver (크롬, 사파리 등)를 제어한 후 나온 페이지(HTML)로부터 크롤링.</li>
</ol>

<h2 id="크롤링-예시">크롤링 예시</h2>
<p>먼저 아래 함수 두개를 지정하겠다.</p>
<ol>
  <li>createDirectory : 입력값으로 받은 문자열(경로)에 해당하는 폴더를 생성한다.</li>
  <li>crawling_img : 입력값으로 받은 문자열을 크롬에서 검색해서 함수내에 지정되어 있는(직접변경) 경로로 이미지를 저장. (이름은 번호순으로 증가)</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time
import urllib.request
import os


def createDirectory(directory):
    try:
        if not os.path.exists(directory):
            os.makedirs(directory)
    except OSError:
        print("Error: Failed to create the directory.")

def crawling_img(name):
    ## 입력값 name 문자열을 검색하여 나오는 이미지를 저장하는 함수.
    ## 저장하는 경로는 함수 내에서 별도로 지정해야함.

    # 크롬을 드라이버로 채택. 버전오류가 날 수 있다.
    driver = webdriver.Chrome()
    driver.get("https://www.google.co.kr/imghp?hl=ko&amp;tab=wi&amp;authuser=0&amp;ogbl")

    # q로 태그되어 있는 곳이 구글홈페이지의 검색창이다.
    elem = driver.find_element_by_name("q")
    elem.send_keys(name)
    elem.send_keys(Keys.RETURN)


    SCROLL_PAUSE_TIME = 1   # 1초씩 기다렸다가 내렸다를 반복할거임.  
    # Get scroll height
    last_height = driver.execute_script("return document.body.scrollHeight")  # 브라우저의 높이를 자바스크립트로 찾음
    while True:
        # Scroll down to bottom
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")  # 브라우저 끝까지 스크롤을 내림
        # Wait to load page
        time.sleep(SCROLL_PAUSE_TIME)
        # Calculate new scroll height and compare with last scroll height
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            try:
                # 더보기 버튼을 클릭할 거임.
                driver.find_element_by_css_selector(".mye4qd").click()
            except:
                # 더보기 버튼이 없어서 클릭을 못하면 끝.
                break
        last_height = new_height

    imgs = driver.find_elements_by_css_selector(".rg_i.Q4LuWd")

    # 경로와 폴더 명 지정.
    dir = ".\tree_flower_dog_cat" + "\\" + name

    createDirectory(dir) #폴더 생성
    count = 1
    for img in imgs:
        try:
            img.click()
            time.sleep(3)
            imgUrl = driver.find_element_by_xpath(
                '//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div/a/img').get_attribute(
                "src")
            path = ".\idols\\" + name + "\\"
            urllib.request.urlretrieve(imgUrl, path + name + "_"+ str(count) + ".jpg")

            # 이 아래는 관련이미지 저장
            imgUrl = driver.find_element_by_xpath(
                '//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[3]/div[3]/c-wiz/div/div/div/div[3]/div[1]/div[1]/a[1]/div[1]/img').get_attribute(
                "src")
            urllib.request.urlretrieve(imgUrl, path + name + "_"+ str(count) + "_1" + ".jpg")
            imgUrl = driver.find_element_by_xpath(
                '//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[3]/div[3]/c-wiz/div/div/div/div[3]/div[1]/div[2]/a[1]/div[1]/img').get_attribute(
                "src")
            urllib.request.urlretrieve(imgUrl, path + name + "_"+ str(count) + "_2" + ".jpg")

            imgUrl = driver.find_element_by_xpath(
                '//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[3]/div[3]/c-wiz/div/div/div/div[3]/div[1]/div[3]/a[1]/div[1]/img').get_attribute(
                "src")
            urllib.request.urlretrieve(imgUrl, path + name + "_"+ str(count) + "_3" + ".jpg")

            count = count + 1
            if count &gt;= 500:
                break
        except:
            pass
    driver.close()
</code></pre></div></div>

<p>이제 위 함수를 사용하여 for문을통해 검색 및 저장을 동시에 해주면 된다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>searching_keyword = ["나무", "꽃", "강아지얼굴", "고양이얼굴"]

for i in range(len(searching_keyword)) :
    searching_keyword[i] += '_사진' # 사진을 뒤에 붙이면 검색이 잘될 것 같아!

for keyword in searching_keyword:
    crawling_img(keyword)
</code></pre></div></div>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="de" /><summary type="html"><![CDATA[크롤링이란 ? web에 있는 데이터들을 긁어모으는 것을 말한다. 크게 두 종류로 먼저 나눌 수 있다. 정적크롤링 : 항상 같은 값을 주는 HTML로 부터 파싱을 해서 크롤링. 동적크롤링 : 같은 HTML이라도 동작, 명령을 통해 변화된 상태에서 데이터들을 크롤링.]]></summary></entry><entry><title type="html">이진분류의 평가지표</title><link href="http://localhost:4000/something_else/_classfication_metrics/" rel="alternate" type="text/html" title="이진분류의 평가지표" /><published>2022-03-02T00:00:00+09:00</published><updated>2022-03-02T00:00:00+09:00</updated><id>http://localhost:4000/something_else/_classfication_metrics</id><content type="html" xml:base="http://localhost:4000/something_else/_classfication_metrics/"><![CDATA[<h2 id="이진분류-모델의-종류">이진분류 모델의 종류</h2>
<p>로지스틱 회귀,<br />
Decision_Tree(base model),<br />
RandomForest,<br />
Gradient_boost,<br />
KNN(K-Nearest-Neighbors),<br />
그외 딥러닝 모델도 될 수 있겠다.</p>

<h2 id="평가지표의-종류">평가지표의 종류</h2>
<p>위와 같은 이진분류 모델 (군집x, 지도학습의 분류o) 의 평가지표는 어떤 게 있을까.<br />
(회귀에서는 MSE, MAE, RMS, R-score 등이 있었쥬!)</p>

<p>가장 단순하게 볼 수 있는 것은 validation 데이터에 대해서 얼마나 많이 맞춘 비율(0~1)이 있을 것이다.<br />
바로 정확도(Accuracy)!  <br />
그러나 모델을 하나의 값으로 평가하면 안될 것이다.</p>

<blockquote>
  <p>정확도 (Accuracy)<br />
먼저 정확도를 체크할 때에도 베이스 모델은 반드시 필요하다.<br />
그 이유를 예로 들어보자면,  암을 예측하는 모델의 학습데이터에서 암에 걸린 데이터(1)가 5%, 나머지 95%가 건강(0)하다면,<br />
입력에 상관없이 항상 출력을 ‘0’으로만 한다면 그 모델은<br />
CV나 hold-out 으로 비슷한 비율로 생성된 validation 데이터에서도 정확도를 대략 0.95로 가질 것이다..!<br />
이러한 모델은 정확도 검증에 있어서 0.95는 최소한 넘는 것으로 고려해야 할 것이다.</p>
</blockquote>

<blockquote>
  <p>TP, TN, FP, FN<br />
(T,F는 True, False,   P,N은 Positive, Negative,)<br />
True는 맞춘거, False는 못맞춘거.<br />
P와 N은 예측한 거 기준. (FP는 실제 Negative인데 모델이 Positive로 예측한거야)</p>
</blockquote>

<blockquote>
  <p>정밀도(precision)와 재현율(recall, sensitivity), specificity(TN-rate), Fall-out<br />
precision = TP/(TP+FP) = Positive로 예측한 것들중 맞춘비율<br />
recall = TP/(TP+FN) = 실제 Positive 중 맞춘비율  (TPRate)
specificity = TN/(TN+FP) = 실제 Negative 중 맞춘비율 (TNR)
Fall-out = FP/(FP+TN) = 실제 Negative 중 틀린비율 (FPR)</p>
</blockquote>

<blockquote>
  <p>confusion Metrics<br />
TP, TN, FP, FN 을 한번에 나타낸 행렬<br />
아래 사진을 참고하면 한번에 이해될것.ㅎㅎ</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.metrics import plot_confusion_matrix
import matplotlib.pyplot as plt

# pipe는 파이프라인
fig, ax = plt.subplots()
matrix = plot_confusion_matrix(pipe, X_val_cleaned, y_val,
                            cmap = plt.cm.Blues,
                            ax = ax);
</code></pre></div></div>
<p><img src="/assets/images/source_23.png" width="30%" height="30%" title="제목" alt="아무거나" /></p>

<blockquote>
  <p>AUC, ROC 와 임계값(Threshold)<br />
ROC 커브는 임계값에 따른 FPR과 TPR 값이 그리는 커브인데. 모두 일대일 관계이다. <br />
AOC수치는 ROC curve의 아래 면적을 뜻한다.<br />
AOC는 클수록 좋은 모델인 것은 사실이다.<br />
이유 : FPR (틀린비율, 낮을수록 좋음) 이 낮음에도 TPR(맞춘비율, 높을수록 좋음)은 높아야 AOC가 높은 것이기 때문.<br />
결과적으로 tpr-fpr이 최대가 되는 점의 임계점을 고르는게 최선이라고 할 수 있다.</p>
</blockquote>

<p><img src="/assets/images/source_24.png" width="30%" height="30%" title="제목" alt="아무거나" /><br />
<img src="/assets/images/source_25.png" width="30%" height="30%" title="제목" alt="아무거나" /></p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="Something_else" /><summary type="html"><![CDATA[이진분류 모델의 종류 로지스틱 회귀, Decision_Tree(base model), RandomForest, Gradient_boost, KNN(K-Nearest-Neighbors), 그외 딥러닝 모델도 될 수 있겠다.]]></summary></entry><entry><title type="html">랜덤포레스트(Random Forest)와 …</title><link href="http://localhost:4000/ds/random_forest/" rel="alternate" type="text/html" title="랜덤포레스트(Random Forest)와 …" /><published>2022-02-28T00:00:00+09:00</published><updated>2022-02-28T00:00:00+09:00</updated><id>http://localhost:4000/ds/random_forest</id><content type="html" xml:base="http://localhost:4000/ds/random_forest/"><![CDATA[<h2 id="랜덤-포레스트-모델">랜덤 포레스트 모델</h2>
<p>단순 선형회귀와 릿지(Ridge) 회귀가 있었다면,<br />
결정트리와 랜덤포레스트가 있다.</p>

<p>릿지 회귀에서 과적합을 방지하는 장치가 있었다.<br />
랜덤포레스트 또한 결정트리에서 더 일반화시켜주는 장치가 있다.</p>

<p>결정트리를 여러개 만들어 모두의 의견을 합산하여 판단을 내린다.</p>

<blockquote>
  <p>숲(포레스트)이 만들어지는 과정</p>
</blockquote>

<ol>
  <li>많은 feature중에서 n개 (pram: max_features) 를 ‘랜덤’으로 고른다.</li>
  <li>n개의 feature중 가장 영향도가 큰 feature를 골라 첫번째 node를 생성하고, 나머지 feature 중 랜덤하게 골라 트리를 완성한다.</li>
  <li>위와같은 트리를 m개(pram: n_estimators)만든다.</li>
  <li>트리들의 분류 결과로 투표를 해서 최종 결정을 한다.</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# bootstrap을 False로 하고 max_features 수정가능.
classifier = RandomForestClassifier(n_estimators = 50, bootstrap = False, max_features = 5)

# 모델 fit
classifier.fit(X_train, y_train)

# 결과값 예측
y_pred = classifier.predict(X_test)

# 같은지 다른지 확인.
print("정확도 : {}".format(accuracy_score(y_test, y_pred))
</code></pre></div></div>

<blockquote>
  <p>CV(cross validation)은 GridsearchCV, RandomizedSearchCV 등을 이용.</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># CV(cross validation)은 gridsearch 등을 이용.
from sklearn.model_selection import GridSearchCV

grid = {
    'n_estimators' : [100,200],
    'max_depth' : [6,8,10,12],
    'min_samples_leaf' : [3,5,7,10],
    'min_samples_split' : [2,3,5,10]
}

classifier_grid = GridSearchCV(classifier, param_grid = grid, scoring="accuracy", n_jobs=-1, verbose =1)

classifier_grid.fit(X_train, y_train)

print("최고 평균 정확도 : {}".format(classifier_grid.best_score_))
print("최고의 파라미터 :", classifier_grid.best_params_)
</code></pre></div></div>
<blockquote>
  <p>feature_importances 내부변수로 확인가능</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

feature_importances = model.feature_importances_

ft_importances = pd.Series(feature_importances, index = X_train.columns)
ft_importances = ft_importances.sort_values(ascending=False)

plt.figure(fig.size(12,10))
sns.barplot(x=ft_importances, y= X_train.columns)
plt.show()
</code></pre></div></div>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[랜덤 포레스트 모델 단순 선형회귀와 릿지(Ridge) 회귀가 있었다면, 결정트리와 랜덤포레스트가 있다.]]></summary></entry><entry><title type="html">파이프라인(PipeLine)과 결정트리모델(Decision Tree)</title><link href="http://localhost:4000/ds/decision_tree/" rel="alternate" type="text/html" title="파이프라인(PipeLine)과 결정트리모델(Decision Tree)" /><published>2022-02-26T00:00:00+09:00</published><updated>2022-02-26T00:00:00+09:00</updated><id>http://localhost:4000/ds/decision_tree</id><content type="html" xml:base="http://localhost:4000/ds/decision_tree/"><![CDATA[<h2 id="사이킷런sklearn-파이프라인-pipeline">사이킷런(sklearn) 파이프라인 (PipeLine)</h2>
<p>사이킷런에서 제공하는 파이프라인은 각 기능을 하는 모델들을 한번에 묶는 기능과<br />
하이퍼 파라미터를 연결시키는 기능이 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.pipeline import make_pipeline
from category_encoders import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier

pipe = make_pipeline(
    OneHotEncoder(use_cat_names=True),  
    SimpleImputer(),
    StandardScaler(),
    DecisionTreeClassifier(random_state=1, criterion='entropy', min_samples_leaf=10, max_depth=6)

    # min_samples_leaf는 말단 노드에 최소 존재해야할 데이터 수.
    # max_depth 는 최대 깊이를 제한하여 복잡도를 개선.
)

# pipe fit
pipe.fit(x_train, y_train)
print('검증세트 정확도', pipe.score(X_val, y_val))

# 테스트 셋
y_pred = pipe.predict(X_test)

# feature_importance 띄우기
## 먼저 파이프 내의 학습된 모델들 떼어서 가져온다.
model_dt = pipe.named_steps['decisiontreeclassifier']
enc = pipe.named_steps['onehotencoder']

encoded_columns = enc.transform(X_val).columns

importances = pd.Series(model_dt.feature_importances_, encoded_columns)
</code></pre></div></div>

<h2 id="결정트리-decision_tree">결정트리 (Decision_Tree)</h2>
<p>결정트리는 ‘분류’에 있어서 마치 ‘회귀’의 선형회귀 와 같은 느낌이다.<br />
데이터들을 계속해서 두가지씩 분류하여 결과적으로 모든 데이터들을 정해진 갯수의 class들로 분류하게 된다.</p>

<p><img src="/assets/images/source_22.png" width="60%" height="60%" title="제목" alt="아무거나" /><br />
결정트리를 발전시킨<br />
‘랜덤포레스트 (Random_Forest)’,<br />
‘그래디언트 부스트 트리 (Gradient Boosted Tree)’<br />
같은 모델들을 더 많이 사용할 것이다.<br />
그러나 그 기초는 결정트리에 있다.</p>

<blockquote>
  <p>트리학습에서의 비용함수</p>
</blockquote>

<ol>
  <li>지니지수 (Gini Impurity</li>
  <li>엔트로피 (Entropy)</li>
</ol>

<p>두가지 모두 불순도를 나타내는 척도 이며<br />
클수록 골고루 섞여 있다는 뜻.(10개의 공들 중에 5개씩 빨간공, 파란공이라면 0.5)
즉, 0에 가까울수록 치우쳐져 있다는 뜻. (전부 특정공만 10개 있다면 0)</p>

<p>즉 지니지수, 엔트로피가 작아지는 방향으로 트리 노드를 생성한다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[사이킷런(sklearn) 파이프라인 (PipeLine) 사이킷런에서 제공하는 파이프라인은 각 기능을 하는 모델들을 한번에 묶는 기능과 하이퍼 파라미터를 연결시키는 기능이 있다.]]></summary></entry><entry><title type="html">특성 선택과 특성 추출</title><link href="http://localhost:4000/something_else/feature_Selection_Extraction/" rel="alternate" type="text/html" title="특성 선택과 특성 추출" /><published>2022-02-25T00:00:00+09:00</published><updated>2022-03-16T00:00:00+09:00</updated><id>http://localhost:4000/something_else/feature_Selection_Extraction</id><content type="html" xml:base="http://localhost:4000/something_else/feature_Selection_Extraction/"><![CDATA[<p>차원을 축소하는 데에는 어떤 방법이 있을까.<br />
첫번째로 영향도 높은 특성을 <strong>‘고르는 것’</strong> 과<br />
두번째는 특성 모두를 특정 축에 <strong>‘투영시키는 것’</strong> 이 있다.</p>

<h1 id="특성-선택-feature-selection">특성 선택 (feature selection)</h1>
<p>특성을 줄이는데, <br />
영향도가 큰 특성을 골라야<br />
모델의 정확도를 유지하면서 복잡도를 줄이거나 일반화를 할 수 있을 것이다.</p>
<h2 id="1-filter-method-전처리-과정에서-통계값으로-선택">1. Filter method (전처리 과정에서 통계값으로 선택.)</h2>
<p>통계값 종류 : 카이제곱, ANOVA_f_score, 상관계수 등.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.feature_selection import chi2, SelectKBest
selector1 = SelectKBest(chi2, k=14330)
X_train1 = selector1.fit_transform(X_train, y_train)
X_test1 = selector1.transform(X_test)
</code></pre></div></div>
<p>↪️ 카이제곱으로 선택한 예시</p>
<h2 id="2-wrapper-method-모델학습과-검정validation을-반복하면서-특성을-선택">2. Wrapper method (모델학습과 검정(validation)을 반복하면서 특성을 선택)</h2>
<p>‘무식한 정답’ 이지만 비합리적인 방법.(greedy 나 grid 단어가 떠오른다.. 왜 발음도 비슷하지ㅎ)<br />
시간과 비용이 많이 소모되며, 상대적으로 filter metthod 보다 과적합되기 쉽다.<br />
forward step, backward step, stepwise 방식이 있는데,<br />
각각 feature를 하나씩 ‘추가’, ‘소거’, ‘추가소거 병합’ 방법이다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from mlxtend.feature_selection import SequentialFeatureSelector

feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1),
           k_features=15,
           forward=True,
           verbose=2,
           scoring='roc_auc',
           cv=4)
features = feature_selector.fit(np.array(X, y)
filtered_features= train_features.columns[list(features.k_feature_idx_)]
#이후 filtered_features로 모델에 fit
</code></pre></div></div>
<p>↪️ mlxtend 라이브러리의 SequentialFeatureSelector 를 사용하여, forward step예시<br />
roc_auc 를 평가지표로, RandomForestClassifier 모델을 이용하여 forward step 기법을 사용.<br />
forward 변수만 False로 바꾸면 backward로 사용</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from mlxtend.feature_selection import ExhaustiveFeatureSelector
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

feature_selector = ExhaustiveFeatureSelector(RandomForestClassifier(n_jobs=-1),
           min_features=2,
           max_features=4,
           scoring='roc_auc',
           print_progress=True,
           cv=2)
features = feature_selector.fit(X, y)
filtered_features= train_features.columns[list(features.k_feature_idx_)]
#이후 filtered_features로 모델에 fit
</code></pre></div></div>
<p>↪️ mlxtend의 ExhaustiveFeatureSelector를 사용한 stepwise 예시<br />
추가소거를 동시에 하는 기법, 최종feature의 최소갯수와 최대갯수를 정한다.</p>
<h2 id="3-embedded-method-학습과-동시에">3. Embedded method (학습과 동시에)</h2>
<p>l1 norm(LASSO회귀에서 사용, 절댓값으로 loss함수 보정),<br />
l2 norm(RIDGE회귀에서 사용, 제곱값으로 loss함수 보정),<br />
elastic_net(l1 + l2),<br />
selectfrommodel(sklearn의 함수를 이용하여, decision Tree기반 모델, 로지스틱등의 모델 등을 통해 feature_importance계산하여 feature 선택)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier
from sklearn.linear_model  import LogisticRegression

# 3가지 모델을 이용해서 feature_importance를 통한 feature선택 모델 설정.
RFselector = SelectFromModel(estimator=RandomForestClassifier()).fit(X, y)
GBMselector = SelectFromModel(estimator=GradientBoostingClassifier()).fit(X, y)
LRselector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)

# feature 보기 (get_support 내부변수를 보면 True, False로 선정 feature를 구별한다)
columns = data.columns
RF_selected = columns[RFselector.get_support()]
GBM_selected = columns[GBMselector.get_support()]
LR_selected = columns[LRselector.get_support()]
</code></pre></div></div>

<h1 id="특성-추출-feature-extraction">특성 추출 (feature extraction)</h1>
<p>대표적으로 pca와 같이 특성들을 <br />
특정 축( 특성들의 특징을 잘 나타내야 한다는 이유로 보통 분산을 최대로하는 축을 선택한다. )에<br />
투영(projection)시켜 차원을 축소하는 방식이 있다.<br />
방법에 대해서는 <a href="https://chan9480.github.io/ds/pca/">https://chan9480.github.io/ds/pca/</a> 에서 조금 다루어놓았다.</p>

<p>한계점을 말하자면
무조건 직선에 투영시킨다는 것.
분산이 큰 특성을 무조건 중요 특성으로 판단한다는 것.</p>
<h1 id="그래서-차원축소-선택할거야-추출할거야">그래서 차원축소… 선택할거야, 추출할거야?</h1>
<p>답은 없겠지만 개인적으로 pca는 시각화나 비지도 군집화에 유용하게 사용되며,<br />
그 외 분류, 회귀 등에는 선택이 많이 쓰인다고 봐도 될 것 같다.<br />
그 중에서도 filter method와 embedded method 의 응용을 앞으로 좀 더 공부해보고자 한다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="Something_else" /><summary type="html"><![CDATA[차원을 축소하는 데에는 어떤 방법이 있을까. 첫번째로 영향도 높은 특성을 ‘고르는 것’ 과 두번째는 특성 모두를 특정 축에 ‘투영시키는 것’ 이 있다.]]></summary></entry><entry><title type="html">Ridge 회귀와 로지스틱 회귀</title><link href="http://localhost:4000/ds/ridge_logistic/" rel="alternate" type="text/html" title="Ridge 회귀와 로지스틱 회귀" /><published>2022-02-25T00:00:00+09:00</published><updated>2022-02-25T00:00:00+09:00</updated><id>http://localhost:4000/ds/ridge_logistic</id><content type="html" xml:base="http://localhost:4000/ds/ridge_logistic/"><![CDATA[<h2 id="cv-교차-검증-cross-validation">CV (교차 검증, cross validation)</h2>
<p>먼저 데이터라고 하면 용도에 따라 3가지로 분류할 수 있다.<br />
학습데이터(training_data),<br />
검증데이터(validation_data),<br />
테스트데이터(test_data)</p>

<p>세가지 데이터는 서로 누출되어서는 안되고,<br />
학습데이터로 학습시킨 ‘모델’ 의<br />
점수는 ‘검증데이터’로 체크를 하되,<br />
마지막으로 타겟 데이터로써 테스트 데이터를 사용한다.</p>

<p>단, CV는 ‘검증데이터’를 따로 두지 않고,<br />
학습데이터를 일부 추출하여 검증데이터로 사용한다는 방식이다.</p>

<p>만약 그저 데이터를 처음부터 ‘학습데이터’와 ‘검증데이터’로 나눈다면 아래와 같을 것이다.<br />
<img src="/assets/images/source_19.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<p>그러나 CV를 이용하게 되면 아래와 같이 학습데이터와 검증데이터가 수시로 바뀌게 되며. 더 <strong>‘일반화’</strong> 된 모델을 얻을 수 있다.<br />
<img src="/assets/images/source_20.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<h2 id="릿지-회귀-ridge-regression">릿지 회귀 (Ridge regression)</h2>
<p>간단하게 Ridge 회귀는 단순회귀보다 더 일반화된 모델을 만든다고 이해해도 좋을 듯 하다.<br />
즉, 단순선형회귀의 과적합 방지 모델.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.linear_model import RidgeCV

# 수행해볼 알파 값들을 정의한다.
alphas = [0.01, 0.05, 0.1, 0.2, 1.0, 10.0, 100.0]

# RidgeCV 모델 객체를 정의한다.
ridge = RidgeCV(alphas=alphas, normalize=True, cv=3)
ridge.fit(ans[['x']], ans['y'])

#결정된 알파와 베스트 스코어를 출력.
print("alpha :", ridge.alpha_)
print("best score :", ridge.best_score_)

# 예측해보고 싶은 X_test에 대해 y
y_pred = ridge.predict(X_test)
</code></pre></div></div>

<h2 id="로지스틱-회귀-logistic-regression">로지스틱 회귀 (logistic Regression)</h2>
<p>로지스틱 회귀는 sigmoid라는 ‘비선형’을 사용한 ‘2진 분류(classification)’ 모델이다.</p>

<p>예시 ) 환자들의 생체 데이터 + 암에 걸리지 않았다면 0, 걸렸다면 1을 갖는 feature (target)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.linear_model import LogisticRegression

model = LogisticRegressionCV(penalty="l1", Cs=[1.0], solver='liblinear', cv=3)
model.fit(X, y)
# 여기서 X는 여러 feature를 갖고 있을 수 있고,
# y는 0이나 1의 값을 갖는 feature일 것이다!

# 스코어 프린트
print('best score: ', model.scores_)

# 테스트 데이터 확인
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test) # proba는 y_pred를 결정했던 근거가 된 각 확률을 보여준다.

# 계수 확인
coefficients = pd.Series(model.coef_[0], X.columns)
coefficients    # 계수가 -1부터 1사이의 값을 갖는데 -1에 가까운 값일 수록 0이 나오게 하는 feature임을 의미
</code></pre></div></div>

<blockquote>
  <p>sigmoid</p>
</blockquote>

<p>x값이 어떤값이든지, y값은 0부터 1사이의 값을 비선형으로 갖도록 하는 함수
<img src="/assets/images/source_21.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<blockquote>
  <p>임계값 (Classification Threshold)</p>
</blockquote>

<p>임계값이 로지스틱 회귀에서 등장했는데,<br />
어떤 데이터 하나가 A에 속할 확률이 0.41이 나왔다고 했을때,<br />
임계값이 0.5(default)라면 당연히 ‘A가 아니다’ 라고 하겠지만,<br />
임계값을 0.4으로 조정한다면 ‘A 이다’ 라고 판단을 내리게 된다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[CV (교차 검증, cross validation) 먼저 데이터라고 하면 용도에 따라 3가지로 분류할 수 있다. 학습데이터(training_data), 검증데이터(validation_data), 테스트데이터(test_data)]]></summary></entry><entry><title type="html">신용카드 데이터로 k-means-cluster, pca 연습</title><link href="http://localhost:4000/pj/Credit_Card_Cluster/" rel="alternate" type="text/html" title="신용카드 데이터로 k-means-cluster, pca 연습" /><published>2022-02-21T00:00:00+09:00</published><updated>2022-02-23T00:00:00+09:00</updated><id>http://localhost:4000/pj/Credit_Card_Cluster</id><content type="html" xml:base="http://localhost:4000/pj/Credit_Card_Cluster/"><![CDATA[<h1 id="데이터-선정-">데이터 선정 :</h1>
<p>kaggle credit customer dataset  (https://www.kaggle.com/arjunbhasin2013/ccdata)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="p">.</span><span class="n">mount</span><span class="p">(</span><span class="s">'/content/drive'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/content/drive/MyDrive/dataset/CC GENERAL.csv.xls'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(8950, 18)
</code></pre></div></div>

<div id="df-0239163e-fb5c-444a-8b2b-314b7f2a8a42">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CUST_ID</th>
      <th>BALANCE</th>
      <th>BALANCE_FREQUENCY</th>
      <th>PURCHASES</th>
      <th>ONEOFF_PURCHASES</th>
      <th>INSTALLMENTS_PURCHASES</th>
      <th>CASH_ADVANCE</th>
      <th>PURCHASES_FREQUENCY</th>
      <th>ONEOFF_PURCHASES_FREQUENCY</th>
      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>
      <th>CASH_ADVANCE_FREQUENCY</th>
      <th>CASH_ADVANCE_TRX</th>
      <th>PURCHASES_TRX</th>
      <th>CREDIT_LIMIT</th>
      <th>PAYMENTS</th>
      <th>MINIMUM_PAYMENTS</th>
      <th>PRC_FULL_PAYMENT</th>
      <th>TENURE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>C10001</td>
      <td>40.900749</td>
      <td>0.818182</td>
      <td>95.40</td>
      <td>0.00</td>
      <td>95.4</td>
      <td>0.000000</td>
      <td>0.166667</td>
      <td>0.000000</td>
      <td>0.083333</td>
      <td>0.000000</td>
      <td>0</td>
      <td>2</td>
      <td>1000.0</td>
      <td>201.802084</td>
      <td>139.509787</td>
      <td>0.000000</td>
      <td>12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>C10002</td>
      <td>3202.467416</td>
      <td>0.909091</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>6442.945483</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.250000</td>
      <td>4</td>
      <td>0</td>
      <td>7000.0</td>
      <td>4103.032597</td>
      <td>1072.340217</td>
      <td>0.222222</td>
      <td>12</td>
    </tr>
    <tr>
      <th>2</th>
      <td>C10003</td>
      <td>2495.148862</td>
      <td>1.000000</td>
      <td>773.17</td>
      <td>773.17</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>12</td>
      <td>7500.0</td>
      <td>622.066742</td>
      <td>627.284787</td>
      <td>0.000000</td>
      <td>12</td>
    </tr>
    <tr>
      <th>3</th>
      <td>C10004</td>
      <td>1666.670542</td>
      <td>0.636364</td>
      <td>1499.00</td>
      <td>1499.00</td>
      <td>0.0</td>
      <td>205.788017</td>
      <td>0.083333</td>
      <td>0.083333</td>
      <td>0.000000</td>
      <td>0.083333</td>
      <td>1</td>
      <td>1</td>
      <td>7500.0</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>0.000000</td>
      <td>12</td>
    </tr>
    <tr>
      <th>4</th>
      <td>C10005</td>
      <td>817.714335</td>
      <td>1.000000</td>
      <td>16.00</td>
      <td>16.00</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.083333</td>
      <td>0.083333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>1</td>
      <td>1200.0</td>
      <td>678.334763</td>
      <td>244.791237</td>
      <td>0.000000</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-0239163e-fb5c-444a-8b2b-314b7f2a8a42')" title="Convert this dataframe to an interactive table." style="display:none;">

  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-0239163e-fb5c-444a-8b2b-314b7f2a8a42 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-0239163e-fb5c-444a-8b2b-314b7f2a8a42');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<h1 id="데이터-확인">데이터 확인</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 결측치 확인
</span><span class="n">df</span><span class="p">.</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CUST_ID                               0
BALANCE                               0
BALANCE_FREQUENCY                     0
PURCHASES                             0
ONEOFF_PURCHASES                      0
INSTALLMENTS_PURCHASES                0
CASH_ADVANCE                          0
PURCHASES_FREQUENCY                   0
ONEOFF_PURCHASES_FREQUENCY            0
PURCHASES_INSTALLMENTS_FREQUENCY      0
CASH_ADVANCE_FREQUENCY                0
CASH_ADVANCE_TRX                      0
PURCHASES_TRX                         0
CREDIT_LIMIT                          1
PAYMENTS                              0
MINIMUM_PAYMENTS                    313
PRC_FULL_PAYMENT                      0
TENURE                                0
dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 데이터 타입 확인
</span><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CUST_ID                              object
BALANCE                             float64
BALANCE_FREQUENCY                   float64
PURCHASES                           float64
ONEOFF_PURCHASES                    float64
INSTALLMENTS_PURCHASES              float64
CASH_ADVANCE                        float64
PURCHASES_FREQUENCY                 float64
ONEOFF_PURCHASES_FREQUENCY          float64
PURCHASES_INSTALLMENTS_FREQUENCY    float64
CASH_ADVANCE_FREQUENCY              float64
CASH_ADVANCE_TRX                      int64
PURCHASES_TRX                         int64
CREDIT_LIMIT                        float64
PAYMENTS                            float64
MINIMUM_PAYMENTS                    float64
PRC_FULL_PAYMENT                    float64
TENURE                                int64
dtype: object
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 결측치 처리 (5%이하의 갯수이므로 드랍하겠다.)
</span><span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(8636, 18)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span> <span class="c1">#경고문을 무시한다.
</span>
<span class="n">i</span><span class="o">=</span><span class="mi">1</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">40</span><span class="p">))</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'CUST_ID'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>

    <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>

    <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/source_11.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 상관 계수 (correlation coefficient) 확인
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff838ba2890&gt;
</code></pre></div></div>

<p><img src="/assets/images/source_12.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<h1 id="표준화-및-pca">표준화 및 PCA</h1>
<p>+축소할 차원 수 결정.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 상관관계가 어느정도 있는 feature가 보이므로 PCA 사용이 유의미할 것으로 판단.
</span><span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'CUST_ID'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># PCA전 표준화
</span><span class="n">ss</span><span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">df</span><span class="o">=</span> <span class="n">ss</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1">#PCA 진행
</span><span class="n">pca</span><span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
<span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PCA()
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PCA 의 축소 차원갯수에 대한 정확도 차이 (기존 차원수를 유지하는게 당연히 100%일것임..)
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">.</span><span class="n">cumsum</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x7ff8393998d0&gt;]
</code></pre></div></div>

<p><img src="/assets/images/source_13.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 차원 축소 7개로 하겠다!
</span><span class="n">pca</span><span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">df_pca</span><span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_pca</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(8636, 7)
</code></pre></div></div>

<h1 id="k-means-clustering">K-means Clustering</h1>
<p>+K-means 와 실루엣 스코어(silhouette_score)</p>

<ul>
  <li>k-means : 각 데이터들과 해당 centroid까지 거리 합</li>
  <li>sil_score : 1에 가까울수록 군집과 군집이 잘 분리되어있다는 뜻<br />
  기본적으로 0이상이고 만약 음수라면 군집끼리 겹쳤다는 의미</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">distortions</span><span class="o">=</span><span class="p">[]</span>
<span class="n">sil_scores</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">):</span>
    <span class="c1"># n_cluster : 군집 갯수, n_iter : 중심점 업데이트의 최소 횟수
</span>    <span class="n">kmeans</span><span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span> <span class="s">'k-means++'</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s">'full'</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_pca</span><span class="p">)</span>
    <span class="c1"># inertia_ : k-means 구하는 중에 centroid로부터 데이터들의 거리 데이터 (클 수록 중심점으로부터 멀다는 거겟쥐)
</span>    <span class="n">distortions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>
    <span class="n">label</span><span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span>
    <span class="n">sil_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">df_pca</span><span class="p">,</span> <span class="n">label</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">distortions</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">distortions</span><span class="p">,</span><span class="s">'o'</span> <span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/source_14.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="c1"># sil_scores 확인
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">sil_scores</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">sil_scores</span><span class="p">,</span><span class="s">'o'</span> <span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/source_15.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sil_scores</span>
<span class="c1"># k-means 는 군집을 늘릴수록 감소 (이상적)
# 실루엣 계수는 3에서 0.28정도로 그나마 크나, 전체적으로는 0.25근처로 별로 크게 나오진 않음.
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.24692450845604266,
 0.28065750721461125,
 0.2507007863496503,
 0.2408710781955889,
 0.25789671860000646,
 0.25543152274952236,
 0.26596171359898996,
 0.25980372706530475,
 0.2606025124276636,
 0.24195602184083095,
 0.25144013095228146,
 0.23962807370519182,
 0.23713138793264468,
 0.23981648640294187,
 0.2199707245532794,
 0.2259075081873923,
 0.23446181289456078,
 0.21832255569020825,
 0.24002990422966186,
 0.23109689399081063,
 0.22381807371604162,
 0.21453215289991348,
 0.21537478705286658,
 0.21174420647359052,
 0.2161573025700017,
 0.21208142071199876,
 0.2196422007478946,
 0.20723949847328374]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># k-means 는 군집 3개로(실루엣계수 따라), PCA는 2개로하여 시각화.
</span>
<span class="n">kmeans</span><span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span> <span class="s">'k-means++'</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s">'full'</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_pca</span><span class="p">)</span>
<span class="n">labels</span><span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span>

<span class="n">pca</span><span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">df_pca2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">temp</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'pca1'</span><span class="p">,</span><span class="s">'pca2'</span><span class="p">])</span>
<span class="n">df_pca2</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span><span class="o">=</span> <span class="n">labels</span>
<span class="n">df_pca2</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div id="df-ed39b30d-40d0-4339-9588-39e85728f5f0">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pca1</th>
      <th>pca2</th>
      <th>labels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.696397</td>
      <td>-1.122594</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.215688</td>
      <td>2.435597</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.935860</td>
      <td>-0.385170</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.614640</td>
      <td>-0.724592</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.223706</td>
      <td>-0.783584</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-ed39b30d-40d0-4339-9588-39e85728f5f0')" title="Convert this dataframe to an interactive table." style="display:none;">

  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-ed39b30d-40d0-4339-9588-39e85728f5f0 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-ed39b30d-40d0-4339-9588-39e85728f5f0');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'pca1'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'pca2'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'labels'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_pca2</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">'bright'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/source_16.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="pj" /><category term="cluster" /><category term="pca" /><summary type="html"><![CDATA[데이터 선정 : kaggle credit customer dataset (https://www.kaggle.com/arjunbhasin2013/ccdata)]]></summary></entry></feed>