<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-03-15T01:36:29+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">배우자 그리고 써먹자</title><subtitle>포트폴리오</subtitle><author><name>옹달샘👱🏼‍♂️</name></author><entry><title type="html">사람얼굴에 스타일 바꿔보기</title><link href="http://localhost:4000/pj/stylegan/" rel="alternate" type="text/html" title="사람얼굴에 스타일 바꿔보기" /><published>2022-03-10T00:00:00+09:00</published><updated>2022-03-13T00:00:00+09:00</updated><id>http://localhost:4000/pj/stylegan</id><content type="html" xml:base="http://localhost:4000/pj/stylegan/"><![CDATA[<h2 id="목표">목표</h2>
<p>임의의 초상권 없는 얼굴을 특정 스타일을 입혀 만들기.</p>

<h2 id="방법">방법</h2>
<p>임시로 생성한 사람얼굴(실존x) 이미지에 원하는 특정 스타일을 가진 사람(실존o)의 이미지를 적용하여 새롭게 생성.</p>

<ol>
  <li>styleGAN2-ada 모델의 ffhq preTrained 가중치를 사용하여 얼굴생성.</li>
  <li>원하는 스타일의 사람사진의 스타일 벡터들을 추출 (PSP 모델의 일부 사용)</li>
  <li>1번에서 생성한 이미지를 inversion하여 다시 이미지를 생성하는 과정에서 2번의 스타일 벡터들을 inject하여 최종 생성.</li>
</ol>

<p><img src="/assets/images/source_26.png" width="100%" height="60%" title="제목" alt="아무거나" /></p>

<h2 id="stylegan2---ada-간단-요약">StyleGAN2 - ada 간단 요약</h2>
<p>GAN (latent vector로 부터 이미지 생성) 모델 중에서<br />
styleGAN (latent vector를 style 별로 생성된 여러 w-vector로 만들어 이미지 생성) 이 있다.</p>

<p>ada는 데이터 증강기법(적은 데이터로 다양한 데이터생성, 일반화 효과 + 데이터 수 늘리는 효과)</p>

<h2 id="psppixel2style2pixel-간단-요약">PSP(pixel2style2pixel) 간단 요약</h2>
<p>구조를 두 부분으로 나눌 수 있는데,</p>
<ol>
  <li>psp encoder : 이미지를 매핑하여 w-vector를 생성함.</li>
  <li>styleGAN generator  : w-vector를 사용하여 이미지를 생성(styleGAN 방식과 같이 해상도를 올리면서 이미지 생성.)</li>
</ol>

<p>이 구조를 이용해서 여러 기능으로 사용가능 (ffhq_encode, celeb_seg_to_face, toonify 등)</p>

<h2 id="test-이미지">test 이미지</h2>
<p>styleGAN2-ada, ffhq-pretrained 로 생성한 이미지 들<br />
<img src="/assets/images/project/test_img0.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img10.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img19.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img4.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img12.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/test_img16.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>

<h2 id="결과-이미지">결과 이미지</h2>
<blockquote>
  <p>스타일이미지</p>
</blockquote>

<p><img src="/assets/images/project/단발.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>
<blockquote>
  <p>결과 이미지<br />
순서대로 <strong>“스타일 적용전”</strong> ::::::: <strong>“w벡터 중 랜덤으로 1 개만 적용”</strong> ::::::: <strong>“모든 w벡터를 적용한 경우”</strong></p>
</blockquote>

<p><img src="/assets/images/project/test_img0.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/0/mask_some.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/0/mask_all.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>

<p><img src="/assets/images/project/test_img10.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/10/mask_some.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/10/mask_all.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>

<p><img src="/assets/images/project/test_img19.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/19/mask_some.png" width="20%" height="60%" title="제목" alt="아무거나" />
<img src="/assets/images/project/19/mask_all.png" width="20%" height="60%" title="제목" alt="아무거나" /></p>

<h2 id="결론">결론</h2>

<p>결과를 해석하자면</p>
<ol>
  <li>스타일이미지의 얼굴형, 머리스타일 등에 원본이미지의 눈코입, 피부 등을 적용시켜 이미지를 생성한다.</li>
  <li>랜덤한 w벡터를 적용했을 때, 스타일 이미지의 정확히 어떤 특징을 담은 w벡터가 적용된 것인지 알기 힘들다..<br />
(물론 스타일이미지와 무언가 닮아지긴 한다.)</li>
</ol>

<p>성공적인가의 여부는 스타일 이라는 애매한 단어에 어떤 걸 포함시키느냐에 따라 해석이 다를 것 같다.<br />
얼굴형, 머리스타일을 ‘스타일’이라고 한다면, 성공에 가깝다고 볼 수 있겠다!<br />
다만 원하는 스타일(머리스타일, 얼굴형 중 하나를 택하고 싶은 경우)을 적용하는데에는 실험적인 시도가 필요해 보인다.</p>

<h2 id="레포지토리-링크">레포지토리 링크</h2>
<p><a href="https://github.com/chan9480/Style_image_GAN">https://github.com/chan9480/Style_image_GAN</a></p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="pj" /><category term="styleGAN2" /><category term="PSP" /><summary type="html"><![CDATA[목표 임의의 초상권 없는 얼굴을 특정 스타일을 입혀 만들기.]]></summary></entry><entry><title type="html">데이터 인코딩(encoding)</title><link href="http://localhost:4000/ds/encoding/" rel="alternate" type="text/html" title="데이터 인코딩(encoding)" /><published>2022-03-06T00:00:00+09:00</published><updated>2022-03-06T00:00:00+09:00</updated><id>http://localhost:4000/ds/encoding</id><content type="html" xml:base="http://localhost:4000/ds/encoding/"><![CDATA[<h2 id="인코딩은-왜-하는거">인코딩은 왜 하는거?</h2>
<p>데이터에는 연속적인 숫자만 있는게 아니다.<br />
문자열의 카테고리형 feature일 수도,<br />
숫자라 하더라도 비연속적인 카테고리형 feature도 있다.<br />
(예: 사는지역(“수유동”, “인수동” …), 평점(“매우별로”,”별로”, … , “매우좋음”))</p>

<p>인코딩은 이러한 카테고리형 feature들에 대하여 ‘데이터’로써 유의미하도록 숫자로 바꿔주는 역할을 한다.</p>

<h2 id="인코딩의-종류와-간단-정리">인코딩의 종류와 간단 정리</h2>
<ol>
  <li>
    <p>One Hot Encoding<br />
하나의 feature가 갖는 범주 전체에 대하여 ‘이다’, ‘아니다’로 분류하여 0, 1을 갖는 feature를 생성.<br />
(사는지역의 종류가 “수유동”, “인수동” 등 16개의 동이 있다면, 16개의 feature (사는지역_수유동… 등)</p>
  </li>
  <li>
    <p>Label Encoding</p>
  </li>
  <li>Ordinal Encoding</li>
  <li>Helmert Encoding</li>
  <li>Binary Encoding</li>
  <li>Frequency Encoding</li>
  <li>Mean Encoding</li>
  <li>Weight of Evidence Encoding</li>
  <li>Probability Ratio Encoding</li>
</ol>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[인코딩은 왜 하는거? 데이터에는 연속적인 숫자만 있는게 아니다. 문자열의 카테고리형 feature일 수도, 숫자라 하더라도 비연속적인 카테고리형 feature도 있다. (예: 사는지역(“수유동”, “인수동” …), 평점(“매우별로”,”별로”, … , “매우좋음”))]]></summary></entry><entry><title type="html">크롤링(Crawling)</title><link href="http://localhost:4000/de/crawling/" rel="alternate" type="text/html" title="크롤링(Crawling)" /><published>2022-03-05T00:00:00+09:00</published><updated>2022-03-05T00:00:00+09:00</updated><id>http://localhost:4000/de/crawling</id><content type="html" xml:base="http://localhost:4000/de/crawling/"><![CDATA[<h2 id="크롤링이란-">크롤링이란 ?</h2>
<p>web에 있는 데이터들을 긁어모으는 것을 말한다.<br />
크게 두 종류로 먼저 나눌 수 있다.</p>
<ol>
  <li>정적크롤링 : 항상 같은 값을 주는 HTML로 부터 파싱을 해서 크롤링.</li>
  <li>동적크롤링 : 같은 HTML이라도 동작, 명령을 통해 변화된 상태에서 데이터들을 크롤링.</li>
</ol>

<p>정적크롤링은 멈춰있는 페이지에서 정보를 찾아 긁어모은다면,<br />
동적크롤링은 검색, 스크롤, 페이지 클릭 등을 해서 나오는 정보를 긁어모을 수 있다.</p>

<p>대표적으로 정적크롤링 관련 라이브러리로 beautifulsoup(bs4)가 있다.<br />
그리고 동적크롤링의 방법에도 여러 종류가 있는데 그 중 2가지를 적어보자면 다음과 같다.</p>
<ol>
  <li>openAPI를 이용하여 명령 후, response된 정보로부터 크롤링.</li>
  <li>selenium을 통해 webdriver (크롬, 사파리 등)를 제어한 후 나온 페이지(HTML)로부터 크롤링.</li>
</ol>

<h2 id="크롤링-예시">크롤링 예시</h2>
<p>먼저 아래 함수 두개를 지정하겠다.</p>
<ol>
  <li>createDirectory : 입력값으로 받은 문자열(경로)에 해당하는 폴더를 생성한다.</li>
  <li>crawling_img : 입력값으로 받은 문자열을 크롬에서 검색해서 함수내에 지정되어 있는(직접변경) 경로로 이미지를 저장. (이름은 번호순으로 증가)</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time
import urllib.request
import os


def createDirectory(directory):
    try:
        if not os.path.exists(directory):
            os.makedirs(directory)
    except OSError:
        print("Error: Failed to create the directory.")

def crawling_img(name):
    ## 입력값 name 문자열을 검색하여 나오는 이미지를 저장하는 함수.
    ## 저장하는 경로는 함수 내에서 별도로 지정해야함.

    # 크롬을 드라이버로 채택. 버전오류가 날 수 있다.
    driver = webdriver.Chrome()
    driver.get("https://www.google.co.kr/imghp?hl=ko&amp;tab=wi&amp;authuser=0&amp;ogbl")

    # q로 태그되어 있는 곳이 구글홈페이지의 검색창이다.
    elem = driver.find_element_by_name("q")
    elem.send_keys(name)
    elem.send_keys(Keys.RETURN)


    SCROLL_PAUSE_TIME = 1   # 1초씩 기다렸다가 내렸다를 반복할거임.  
    # Get scroll height
    last_height = driver.execute_script("return document.body.scrollHeight")  # 브라우저의 높이를 자바스크립트로 찾음
    while True:
        # Scroll down to bottom
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")  # 브라우저 끝까지 스크롤을 내림
        # Wait to load page
        time.sleep(SCROLL_PAUSE_TIME)
        # Calculate new scroll height and compare with last scroll height
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            try:
                # 더보기 버튼을 클릭할 거임.
                driver.find_element_by_css_selector(".mye4qd").click()
            except:
                # 더보기 버튼이 없어서 클릭을 못하면 끝.
                break
        last_height = new_height

    imgs = driver.find_elements_by_css_selector(".rg_i.Q4LuWd")

    # 경로와 폴더 명 지정.
    dir = ".\tree_flower_dog_cat" + "\\" + name

    createDirectory(dir) #폴더 생성
    count = 1
    for img in imgs:
        try:
            img.click()
            time.sleep(3)
            imgUrl = driver.find_element_by_xpath(
                '//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div/a/img').get_attribute(
                "src")
            path = ".\idols\\" + name + "\\"
            urllib.request.urlretrieve(imgUrl, path + name + "_"+ str(count) + ".jpg")

            # 이 아래는 관련이미지 저장
            imgUrl = driver.find_element_by_xpath(
                '//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[3]/div[3]/c-wiz/div/div/div/div[3]/div[1]/div[1]/a[1]/div[1]/img').get_attribute(
                "src")
            urllib.request.urlretrieve(imgUrl, path + name + "_"+ str(count) + "_1" + ".jpg")
            imgUrl = driver.find_element_by_xpath(
                '//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[3]/div[3]/c-wiz/div/div/div/div[3]/div[1]/div[2]/a[1]/div[1]/img').get_attribute(
                "src")
            urllib.request.urlretrieve(imgUrl, path + name + "_"+ str(count) + "_2" + ".jpg")

            imgUrl = driver.find_element_by_xpath(
                '//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[3]/div[3]/c-wiz/div/div/div/div[3]/div[1]/div[3]/a[1]/div[1]/img').get_attribute(
                "src")
            urllib.request.urlretrieve(imgUrl, path + name + "_"+ str(count) + "_3" + ".jpg")

            count = count + 1
            if count &gt;= 500:
                break
        except:
            pass
    driver.close()
</code></pre></div></div>

<p>이제 위 함수를 사용하여 for문을통해 검색 및 저장을 동시에 해주면 된다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>searching_keyword = ["나무", "꽃", "강아지얼굴", "고양이얼굴"]

for i in range(len(searching_keyword)) :
    searching_keyword[i] += '_사진' # 사진을 뒤에 붙이면 검색이 잘될 것 같아!

for keyword in searching_keyword:
    crawling_img(keyword)
</code></pre></div></div>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="de" /><summary type="html"><![CDATA[크롤링이란 ? web에 있는 데이터들을 긁어모으는 것을 말한다. 크게 두 종류로 먼저 나눌 수 있다. 정적크롤링 : 항상 같은 값을 주는 HTML로 부터 파싱을 해서 크롤링. 동적크롤링 : 같은 HTML이라도 동작, 명령을 통해 변화된 상태에서 데이터들을 크롤링.]]></summary></entry><entry><title type="html">이진분류의 평가지표</title><link href="http://localhost:4000/something_else/_classfication_metrics/" rel="alternate" type="text/html" title="이진분류의 평가지표" /><published>2022-03-02T00:00:00+09:00</published><updated>2022-03-02T00:00:00+09:00</updated><id>http://localhost:4000/something_else/_classfication_metrics</id><content type="html" xml:base="http://localhost:4000/something_else/_classfication_metrics/"><![CDATA[<h2 id="이진분류-모델의-종류">이진분류 모델의 종류</h2>
<p>로지스틱 회귀,<br />
Decision_Tree(base model),<br />
RandomForest,<br />
Gradient_boost,<br />
KNN(K-Nearest-Neighbors),<br />
그외 딥러닝 모델도 될 수 있겠다.</p>

<h2 id="평가지표의-종류">평가지표의 종류</h2>
<p>위와 같은 이진분류 모델 (군집x, 지도학습의 분류o) 의 평가지표는 어떤 게 있을까.<br />
(회귀에서는 MSE, MAE, RMS, R-score 등이 있었쥬!)</p>

<p>가장 단순하게 볼 수 있는 것은 validation 데이터에 대해서 얼마나 많이 맞춘 비율(0~1)이 있을 것이다.<br />
바로 정확도(Accuracy)!  <br />
그러나 모델을 하나의 값으로 평가하면 안될 것이다.</p>

<blockquote>
  <p>정확도 (Accuracy)<br />
먼저 정확도를 체크할 때에도 베이스 모델은 반드시 필요하다.<br />
그 이유를 예로 들어보자면,  암을 예측하는 모델의 학습데이터에서 암에 걸린 데이터(1)가 5%, 나머지 95%가 건강(0)하다면,<br />
입력에 상관없이 항상 출력을 ‘0’으로만 한다면 그 모델은<br />
CV나 hold-out 으로 비슷한 비율로 생성된 validation 데이터에서도 정확도를 대략 0.95로 가질 것이다..!<br />
이러한 모델은 정확도 검증에 있어서 0.95는 최소한 넘는 것으로 고려해야 할 것이다.</p>
</blockquote>

<blockquote>
  <p>TP, TN, FP, FN<br />
(T,F는 True, False,   P,N은 Positive, Negative,)<br />
True는 맞춘거, False는 못맞춘거.<br />
P와 N은 예측한 거 기준. (FP는 실제 Negative인데 모델이 Positive로 예측한거야)</p>
</blockquote>

<blockquote>
  <p>정밀도(precision)와 재현율(recall, sensitivity), specificity(TN-rate), Fall-out<br />
precision = TP/(TP+FP) = Positive로 예측한 것들중 맞춘비율<br />
recall = TP/(TP+FN) = 실제 Positive 중 맞춘비율  (TPRate)
specificity = TN/(TN+FP) = 실제 Negative 중 맞춘비율 (TNR)
Fall-out = FP/(FP+TN) = 실제 Negative 중 틀린비율 (FPR)</p>
</blockquote>

<blockquote>
  <p>confusion Metrics<br />
TP, TN, FP, FN 을 한번에 나타낸 행렬<br />
아래 사진을 참고하면 한번에 이해될것.ㅎㅎ</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.metrics import plot_confusion_matrix
import matplotlib.pyplot as plt

# pipe는 파이프라인
fig, ax = plt.subplots()
matrix = plot_confusion_matrix(pipe, X_val_cleaned, y_val,
                            cmap = plt.cm.Blues,
                            ax = ax);
</code></pre></div></div>
<p><img src="/assets/images/source_23.png" width="30%" height="30%" title="제목" alt="아무거나" /></p>

<blockquote>
  <p>AUC, ROC 와 임계값(Threshold)<br />
ROC 커브는 임계값에 따른 FPR과 TPR 값이 그리는 커브인데. 모두 일대일 관계이다. <br />
AOC수치는 ROC curve의 아래 면적을 뜻한다.<br />
AOC는 클수록 좋은 모델인 것은 사실이다.<br />
이유 : FPR (틀린비율, 낮을수록 좋음) 이 낮음에도 TPR(맞춘비율, 높을수록 좋음)은 높아야 AOC가 높은 것이기 때문.<br />
결과적으로 tpr-fpr이 최대가 되는 점의 임계점을 고르는게 최선이라고 할 수 있다.</p>
</blockquote>

<p><img src="/assets/images/source_24.png" width="30%" height="30%" title="제목" alt="아무거나" /><br />
<img src="/assets/images/source_25.png" width="30%" height="30%" title="제목" alt="아무거나" /></p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="Something_else" /><summary type="html"><![CDATA[이진분류 모델의 종류 로지스틱 회귀, Decision_Tree(base model), RandomForest, Gradient_boost, KNN(K-Nearest-Neighbors), 그외 딥러닝 모델도 될 수 있겠다.]]></summary></entry><entry><title type="html">랜덤포레스트(Random Forest)와 …</title><link href="http://localhost:4000/ds/random_forest/" rel="alternate" type="text/html" title="랜덤포레스트(Random Forest)와 …" /><published>2022-02-28T00:00:00+09:00</published><updated>2022-02-28T00:00:00+09:00</updated><id>http://localhost:4000/ds/random_forest</id><content type="html" xml:base="http://localhost:4000/ds/random_forest/"><![CDATA[<h2 id="랜덤-포레스트-모델">랜덤 포레스트 모델</h2>
<p>단순 선형회귀와 릿지(Ridge) 회귀가 있었다면,<br />
결정트리와 랜덤포레스트가 있다.</p>

<p>릿지 회귀에서 과적합을 방지하는 장치가 있었다.<br />
랜덤포레스트 또한 결정트리에서 더 일반화시켜주는 장치가 있다.</p>

<p>결정트리를 여러개 만들어 모두의 의견을 합산하여 판단을 내린다.</p>

<blockquote>
  <p>숲(포레스트)이 만들어지는 과정</p>
</blockquote>

<ol>
  <li>많은 feature중에서 n개 (pram: max_features) 를 ‘랜덤’으로 고른다.</li>
  <li>n개의 feature중 가장 영향도가 큰 feature를 골라 첫번째 node를 생성하고, 나머지 feature 중 랜덤하게 골라 트리를 완성한다.</li>
  <li>위와같은 트리를 m개(pram: n_estimators)만든다.</li>
  <li>트리들의 분류 결과로 투표를 해서 최종 결정을 한다.</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# bootstrap을 False로 하고 max_features 수정가능.
classifier = RandomForestClassifier(n_estimators = 50, bootstrap = False, max_features = 5)

# 모델 fit
classifier.fit(X_train, y_train)

# 결과값 예측
y_pred = classifier.predict(X_test)

# 같은지 다른지 확인.
print("정확도 : {}".format(accuracy_score(y_test, y_pred))
</code></pre></div></div>

<blockquote>
  <p>CV(cross validation)은 GridsearchCV, RandomizedSearchCV 등을 이용.</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># CV(cross validation)은 gridsearch 등을 이용.
from sklearn.model_selection import GridSearchCV

grid = {
    'n_estimators' : [100,200],
    'max_depth' : [6,8,10,12],
    'min_samples_leaf' : [3,5,7,10],
    'min_samples_split' : [2,3,5,10]
}

classifier_grid = GridSearchCV(classifier, param_grid = grid, scoring="accuracy", n_jobs=-1, verbose =1)

classifier_grid.fit(X_train, y_train)

print("최고 평균 정확도 : {}".format(classifier_grid.best_score_))
print("최고의 파라미터 :", classifier_grid.best_params_)
</code></pre></div></div>
<blockquote>
  <p>feature_importances 내부변수로 확인가능</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

feature_importances = model.feature_importances_

ft_importances = pd.Series(feature_importances, index = X_train.columns)
ft_importances = ft_importances.sort_values(ascending=False)

plt.figure(fig.size(12,10))
sns.barplot(x=ft_importances, y= X_train.columns)
plt.show()
</code></pre></div></div>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[랜덤 포레스트 모델 단순 선형회귀와 릿지(Ridge) 회귀가 있었다면, 결정트리와 랜덤포레스트가 있다.]]></summary></entry><entry><title type="html">파이프라인(PipeLine)과 결정트리모델(Decision Tree)</title><link href="http://localhost:4000/ds/decision_tree/" rel="alternate" type="text/html" title="파이프라인(PipeLine)과 결정트리모델(Decision Tree)" /><published>2022-02-26T00:00:00+09:00</published><updated>2022-02-26T00:00:00+09:00</updated><id>http://localhost:4000/ds/decision_tree</id><content type="html" xml:base="http://localhost:4000/ds/decision_tree/"><![CDATA[<h2 id="사이킷런sklearn-파이프라인-pipeline">사이킷런(sklearn) 파이프라인 (PipeLine)</h2>
<p>사이킷런에서 제공하는 파이프라인은 각 기능을 하는 모델들을 한번에 묶는 기능과<br />
하이퍼 파라미터를 연결시키는 기능이 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.pipeline import make_pipeline
from category_encoders import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier

pipe = make_pipeline(
    OneHotEncoder(use_cat_names=True),  
    SimpleImputer(),
    StandardScaler(),
    DecisionTreeClassifier(random_state=1, criterion='entropy', min_samples_leaf=10, max_depth=6)

    # min_samples_leaf는 말단 노드에 최소 존재해야할 데이터 수.
    # max_depth 는 최대 깊이를 제한하여 복잡도를 개선.
)

# pipe fit
pipe.fit(x_train, y_train)
print('검증세트 정확도', pipe.score(X_val, y_val))

# 테스트 셋
y_pred = pipe.predict(X_test)

# feature_importance 띄우기
## 먼저 파이프 내의 학습된 모델들 떼어서 가져온다.
model_dt = pipe.named_steps['decisiontreeclassifier']
enc = pipe.named_steps['onehotencoder']

encoded_columns = enc.transform(X_val).columns

importances = pd.Series(model_dt.feature_importances_, encoded_columns)
</code></pre></div></div>

<h2 id="결정트리-decision_tree">결정트리 (Decision_Tree)</h2>
<p>결정트리는 ‘분류’에 있어서 마치 ‘회귀’의 선형회귀 와 같은 느낌이다.<br />
데이터들을 계속해서 두가지씩 분류하여 결과적으로 모든 데이터들을 정해진 갯수의 class들로 분류하게 된다.</p>

<p><img src="/assets/images/source_22.png" width="60%" height="60%" title="제목" alt="아무거나" /><br />
결정트리를 발전시킨<br />
‘랜덤포레스트 (Random_Forest)’,<br />
‘그래디언트 부스트 트리 (Gradient Boosted Tree)’<br />
같은 모델들을 더 많이 사용할 것이다.<br />
그러나 그 기초는 결정트리에 있다.</p>

<blockquote>
  <p>트리학습에서의 비용함수</p>
</blockquote>

<ol>
  <li>지니지수 (Gini Impurity</li>
  <li>엔트로피 (Entropy)</li>
</ol>

<p>두가지 모두 불순도를 나타내는 척도 이며<br />
클수록 골고루 섞여 있다는 뜻.(10개의 공들 중에 5개씩 빨간공, 파란공이라면 0.5)
즉, 0에 가까울수록 치우쳐져 있다는 뜻. (전부 특정공만 10개 있다면 0)</p>

<p>즉 지니지수, 엔트로피가 작아지는 방향으로 트리 노드를 생성한다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[사이킷런(sklearn) 파이프라인 (PipeLine) 사이킷런에서 제공하는 파이프라인은 각 기능을 하는 모델들을 한번에 묶는 기능과 하이퍼 파라미터를 연결시키는 기능이 있다.]]></summary></entry><entry><title type="html">특성 선택과 특성 추출</title><link href="http://localhost:4000/something_else/feature_Selection_Extraction/" rel="alternate" type="text/html" title="특성 선택과 특성 추출" /><published>2022-02-25T00:00:00+09:00</published><updated>2022-02-25T00:00:00+09:00</updated><id>http://localhost:4000/something_else/feature_Selection_Extraction</id><content type="html" xml:base="http://localhost:4000/something_else/feature_Selection_Extraction/"><![CDATA[<p>특성을 줄이는데에는 어떤 방법이 있을까.<br />
첫번째로 영향도 높은 특성을 <strong>‘고르는 것’</strong> 과<br />
두번째는 특성 모두 특정 축에 <strong>‘투영시키는 것’</strong> 이 있다.</p>

<h2 id="특성-선택-feature-selection">특성 선택 (feature selection)</h2>
<p>특성을 줄이는데, <br />
영향도가 큰 특성을 골라야<br />
모델의 정확도를 유지하면서 복잡도를 줄이거나 일반화를 할 수 있을 것이다.</p>

<h2 id="특성-추출-feature-extraction">특성 추출 (feature extraction)</h2>
<p>대표적으로 pca와 같이 특성들을 <br />
특정 축( 특성들의 특징을 잘 나타내야 한다는 이유로 보통 분산을 최대로하는 축을 선택한다. )에<br />
투영(projection)시켜 차원을 축소하는 방식이 있다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="Something_else" /><summary type="html"><![CDATA[특성을 줄이는데에는 어떤 방법이 있을까. 첫번째로 영향도 높은 특성을 ‘고르는 것’ 과 두번째는 특성 모두 특정 축에 ‘투영시키는 것’ 이 있다.]]></summary></entry><entry><title type="html">Ridge 회귀와 로지스틱 회귀</title><link href="http://localhost:4000/ds/ridge_logistic/" rel="alternate" type="text/html" title="Ridge 회귀와 로지스틱 회귀" /><published>2022-02-25T00:00:00+09:00</published><updated>2022-02-25T00:00:00+09:00</updated><id>http://localhost:4000/ds/ridge_logistic</id><content type="html" xml:base="http://localhost:4000/ds/ridge_logistic/"><![CDATA[<h2 id="cv-교차-검증-cross-validation">CV (교차 검증, cross validation)</h2>
<p>먼저 데이터라고 하면 용도에 따라 3가지로 분류할 수 있다.<br />
학습데이터(training_data),<br />
검증데이터(validation_data),<br />
테스트데이터(test_data)</p>

<p>세가지 데이터는 서로 누출되어서는 안되고,<br />
학습데이터로 학습시킨 ‘모델’ 의<br />
점수는 ‘검증데이터’로 체크를 하되,<br />
마지막으로 타겟 데이터로써 테스트 데이터를 사용한다.</p>

<p>단, CV는 ‘검증데이터’를 따로 두지 않고,<br />
학습데이터를 일부 추출하여 검증데이터로 사용한다는 방식이다.</p>

<p>만약 그저 데이터를 처음부터 ‘학습데이터’와 ‘검증데이터’로 나눈다면 아래와 같을 것이다.<br />
<img src="/assets/images/source_19.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<p>그러나 CV를 이용하게 되면 아래와 같이 학습데이터와 검증데이터가 수시로 바뀌게 되며. 더 <strong>‘일반화’</strong> 된 모델을 얻을 수 있다.<br />
<img src="/assets/images/source_20.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<h2 id="릿지-회귀-ridge-regression">릿지 회귀 (Ridge regression)</h2>
<p>간단하게 Ridge 회귀는 단순회귀보다 더 일반화된 모델을 만든다고 이해해도 좋을 듯 하다.<br />
즉, 단순선형회귀의 과적합 방지 모델.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.linear_model import RidgeCV

# 수행해볼 알파 값들을 정의한다.
alphas = [0.01, 0.05, 0.1, 0.2, 1.0, 10.0, 100.0]

# RidgeCV 모델 객체를 정의한다.
ridge = RidgeCV(alphas=alphas, normalize=True, cv=3)
ridge.fit(ans[['x']], ans['y'])

#결정된 알파와 베스트 스코어를 출력.
print("alpha :", ridge.alpha_)
print("best score :", ridge.best_score_)

# 예측해보고 싶은 X_test에 대해 y
y_pred = ridge.predict(X_test)
</code></pre></div></div>

<h2 id="로지스틱-회귀-logistic-regression">로지스틱 회귀 (logistic Regression)</h2>
<p>로지스틱 회귀는 sigmoid라는 ‘비선형’을 사용한 ‘2진 분류(classification)’ 모델이다.</p>

<p>예시 ) 환자들의 생체 데이터 + 암에 걸리지 않았다면 0, 걸렸다면 1을 갖는 feature (target)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.linear_model import LogisticRegression

model = LogisticRegressionCV(penalty="l1", Cs=[1.0], solver='liblinear', cv=3)
model.fit(X, y)
# 여기서 X는 여러 feature를 갖고 있을 수 있고,
# y는 0이나 1의 값을 갖는 feature일 것이다!

# 스코어 프린트
print('best score: ', model.scores_)

# 테스트 데이터 확인
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test) # proba는 y_pred를 결정했던 근거가 된 각 확률을 보여준다.

# 계수 확인
coefficients = pd.Series(model.coef_[0], X.columns)
coefficients    # 계수가 -1부터 1사이의 값을 갖는데 -1에 가까운 값일 수록 0이 나오게 하는 feature임을 의미
</code></pre></div></div>

<blockquote>
  <p>sigmoid</p>
</blockquote>

<p>x값이 어떤값이든지, y값은 0부터 1사이의 값을 비선형으로 갖도록 하는 함수
<img src="/assets/images/source_21.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<blockquote>
  <p>임계값 (Classification Threshold)</p>
</blockquote>

<p>임계값이 로지스틱 회귀에서 등장했는데,<br />
어떤 데이터 하나가 A에 속할 확률이 0.41이 나왔다고 했을때,<br />
임계값이 0.5(default)라면 당연히 ‘A가 아니다’ 라고 하겠지만,<br />
임계값을 0.4으로 조정한다면 ‘A 이다’ 라고 판단을 내리게 된다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[CV (교차 검증, cross validation) 먼저 데이터라고 하면 용도에 따라 3가지로 분류할 수 있다. 학습데이터(training_data), 검증데이터(validation_data), 테스트데이터(test_data)]]></summary></entry><entry><title type="html">신용카드 데이터로 k-means-cluster, pca 연습</title><link href="http://localhost:4000/pj/Credit_Card_Cluster/" rel="alternate" type="text/html" title="신용카드 데이터로 k-means-cluster, pca 연습" /><published>2022-02-21T00:00:00+09:00</published><updated>2022-02-23T00:00:00+09:00</updated><id>http://localhost:4000/pj/Credit_Card_Cluster</id><content type="html" xml:base="http://localhost:4000/pj/Credit_Card_Cluster/"><![CDATA[<h1 id="데이터-선정-">데이터 선정 :</h1>
<p>kaggle credit customer dataset  (https://www.kaggle.com/arjunbhasin2013/ccdata)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="p">.</span><span class="n">mount</span><span class="p">(</span><span class="s">'/content/drive'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/content/drive/MyDrive/dataset/CC GENERAL.csv.xls'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(8950, 18)
</code></pre></div></div>

<div id="df-0239163e-fb5c-444a-8b2b-314b7f2a8a42">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CUST_ID</th>
      <th>BALANCE</th>
      <th>BALANCE_FREQUENCY</th>
      <th>PURCHASES</th>
      <th>ONEOFF_PURCHASES</th>
      <th>INSTALLMENTS_PURCHASES</th>
      <th>CASH_ADVANCE</th>
      <th>PURCHASES_FREQUENCY</th>
      <th>ONEOFF_PURCHASES_FREQUENCY</th>
      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>
      <th>CASH_ADVANCE_FREQUENCY</th>
      <th>CASH_ADVANCE_TRX</th>
      <th>PURCHASES_TRX</th>
      <th>CREDIT_LIMIT</th>
      <th>PAYMENTS</th>
      <th>MINIMUM_PAYMENTS</th>
      <th>PRC_FULL_PAYMENT</th>
      <th>TENURE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>C10001</td>
      <td>40.900749</td>
      <td>0.818182</td>
      <td>95.40</td>
      <td>0.00</td>
      <td>95.4</td>
      <td>0.000000</td>
      <td>0.166667</td>
      <td>0.000000</td>
      <td>0.083333</td>
      <td>0.000000</td>
      <td>0</td>
      <td>2</td>
      <td>1000.0</td>
      <td>201.802084</td>
      <td>139.509787</td>
      <td>0.000000</td>
      <td>12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>C10002</td>
      <td>3202.467416</td>
      <td>0.909091</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>6442.945483</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.250000</td>
      <td>4</td>
      <td>0</td>
      <td>7000.0</td>
      <td>4103.032597</td>
      <td>1072.340217</td>
      <td>0.222222</td>
      <td>12</td>
    </tr>
    <tr>
      <th>2</th>
      <td>C10003</td>
      <td>2495.148862</td>
      <td>1.000000</td>
      <td>773.17</td>
      <td>773.17</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>12</td>
      <td>7500.0</td>
      <td>622.066742</td>
      <td>627.284787</td>
      <td>0.000000</td>
      <td>12</td>
    </tr>
    <tr>
      <th>3</th>
      <td>C10004</td>
      <td>1666.670542</td>
      <td>0.636364</td>
      <td>1499.00</td>
      <td>1499.00</td>
      <td>0.0</td>
      <td>205.788017</td>
      <td>0.083333</td>
      <td>0.083333</td>
      <td>0.000000</td>
      <td>0.083333</td>
      <td>1</td>
      <td>1</td>
      <td>7500.0</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>0.000000</td>
      <td>12</td>
    </tr>
    <tr>
      <th>4</th>
      <td>C10005</td>
      <td>817.714335</td>
      <td>1.000000</td>
      <td>16.00</td>
      <td>16.00</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.083333</td>
      <td>0.083333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>1</td>
      <td>1200.0</td>
      <td>678.334763</td>
      <td>244.791237</td>
      <td>0.000000</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-0239163e-fb5c-444a-8b2b-314b7f2a8a42')" title="Convert this dataframe to an interactive table." style="display:none;">

  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-0239163e-fb5c-444a-8b2b-314b7f2a8a42 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-0239163e-fb5c-444a-8b2b-314b7f2a8a42');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<h1 id="데이터-확인">데이터 확인</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 결측치 확인
</span><span class="n">df</span><span class="p">.</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CUST_ID                               0
BALANCE                               0
BALANCE_FREQUENCY                     0
PURCHASES                             0
ONEOFF_PURCHASES                      0
INSTALLMENTS_PURCHASES                0
CASH_ADVANCE                          0
PURCHASES_FREQUENCY                   0
ONEOFF_PURCHASES_FREQUENCY            0
PURCHASES_INSTALLMENTS_FREQUENCY      0
CASH_ADVANCE_FREQUENCY                0
CASH_ADVANCE_TRX                      0
PURCHASES_TRX                         0
CREDIT_LIMIT                          1
PAYMENTS                              0
MINIMUM_PAYMENTS                    313
PRC_FULL_PAYMENT                      0
TENURE                                0
dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 데이터 타입 확인
</span><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CUST_ID                              object
BALANCE                             float64
BALANCE_FREQUENCY                   float64
PURCHASES                           float64
ONEOFF_PURCHASES                    float64
INSTALLMENTS_PURCHASES              float64
CASH_ADVANCE                        float64
PURCHASES_FREQUENCY                 float64
ONEOFF_PURCHASES_FREQUENCY          float64
PURCHASES_INSTALLMENTS_FREQUENCY    float64
CASH_ADVANCE_FREQUENCY              float64
CASH_ADVANCE_TRX                      int64
PURCHASES_TRX                         int64
CREDIT_LIMIT                        float64
PAYMENTS                            float64
MINIMUM_PAYMENTS                    float64
PRC_FULL_PAYMENT                    float64
TENURE                                int64
dtype: object
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 결측치 처리 (5%이하의 갯수이므로 드랍하겠다.)
</span><span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(8636, 18)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span> <span class="c1">#경고문을 무시한다.
</span>
<span class="n">i</span><span class="o">=</span><span class="mi">1</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">40</span><span class="p">))</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'CUST_ID'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>

    <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>

    <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/source_11.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 상관 계수 (correlation coefficient) 확인
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff838ba2890&gt;
</code></pre></div></div>

<p><img src="/assets/images/source_12.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<h1 id="표준화-및-pca">표준화 및 PCA</h1>
<p>+축소할 차원 수 결정.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 상관관계가 어느정도 있는 feature가 보이므로 PCA 사용이 유의미할 것으로 판단.
</span><span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'CUST_ID'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># PCA전 표준화
</span><span class="n">ss</span><span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">df</span><span class="o">=</span> <span class="n">ss</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1">#PCA 진행
</span><span class="n">pca</span><span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
<span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PCA()
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PCA 의 축소 차원갯수에 대한 정확도 차이 (기존 차원수를 유지하는게 당연히 100%일것임..)
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">.</span><span class="n">cumsum</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x7ff8393998d0&gt;]
</code></pre></div></div>

<p><img src="/assets/images/source_13.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 차원 축소 7개로 하겠다!
</span><span class="n">pca</span><span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">df_pca</span><span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_pca</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(8636, 7)
</code></pre></div></div>

<h1 id="k-means-clustering">K-means Clustering</h1>
<p>+K-means 와 실루엣 스코어(silhouette_score)</p>

<ul>
  <li>k-means : 각 데이터들과 해당 centroid까지 거리 합</li>
  <li>sil_score : 1에 가까울수록 군집과 군집이 잘 분리되어있다는 뜻<br />
  기본적으로 0이상이고 만약 음수라면 군집끼리 겹쳤다는 의미</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">distortions</span><span class="o">=</span><span class="p">[]</span>
<span class="n">sil_scores</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">):</span>
    <span class="c1"># n_cluster : 군집 갯수, n_iter : 중심점 업데이트의 최소 횟수
</span>    <span class="n">kmeans</span><span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span> <span class="s">'k-means++'</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s">'full'</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_pca</span><span class="p">)</span>
    <span class="c1"># inertia_ : k-means 구하는 중에 centroid로부터 데이터들의 거리 데이터 (클 수록 중심점으로부터 멀다는 거겟쥐)
</span>    <span class="n">distortions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>
    <span class="n">label</span><span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span>
    <span class="n">sil_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">df_pca</span><span class="p">,</span> <span class="n">label</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">distortions</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">distortions</span><span class="p">,</span><span class="s">'o'</span> <span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/source_14.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="c1"># sil_scores 확인
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">sil_scores</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">sil_scores</span><span class="p">,</span><span class="s">'o'</span> <span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/source_15.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sil_scores</span>
<span class="c1"># k-means 는 군집을 늘릴수록 감소 (이상적)
# 실루엣 계수는 3에서 0.28정도로 그나마 크나, 전체적으로는 0.25근처로 별로 크게 나오진 않음.
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.24692450845604266,
 0.28065750721461125,
 0.2507007863496503,
 0.2408710781955889,
 0.25789671860000646,
 0.25543152274952236,
 0.26596171359898996,
 0.25980372706530475,
 0.2606025124276636,
 0.24195602184083095,
 0.25144013095228146,
 0.23962807370519182,
 0.23713138793264468,
 0.23981648640294187,
 0.2199707245532794,
 0.2259075081873923,
 0.23446181289456078,
 0.21832255569020825,
 0.24002990422966186,
 0.23109689399081063,
 0.22381807371604162,
 0.21453215289991348,
 0.21537478705286658,
 0.21174420647359052,
 0.2161573025700017,
 0.21208142071199876,
 0.2196422007478946,
 0.20723949847328374]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># k-means 는 군집 3개로(실루엣계수 따라), PCA는 2개로하여 시각화.
</span>
<span class="n">kmeans</span><span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span> <span class="s">'k-means++'</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s">'full'</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_pca</span><span class="p">)</span>
<span class="n">labels</span><span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span>

<span class="n">pca</span><span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">df_pca2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">temp</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'pca1'</span><span class="p">,</span><span class="s">'pca2'</span><span class="p">])</span>
<span class="n">df_pca2</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span><span class="o">=</span> <span class="n">labels</span>
<span class="n">df_pca2</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div id="df-ed39b30d-40d0-4339-9588-39e85728f5f0">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pca1</th>
      <th>pca2</th>
      <th>labels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.696397</td>
      <td>-1.122594</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.215688</td>
      <td>2.435597</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.935860</td>
      <td>-0.385170</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.614640</td>
      <td>-0.724592</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.223706</td>
      <td>-0.783584</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-ed39b30d-40d0-4339-9588-39e85728f5f0')" title="Convert this dataframe to an interactive table." style="display:none;">

  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-ed39b30d-40d0-4339-9588-39e85728f5f0 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-ed39b30d-40d0-4339-9588-39e85728f5f0');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'pca1'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'pca2'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'labels'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_pca2</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">'bright'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/source_16.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="pj" /><category term="cluster" /><category term="pca" /><summary type="html"><![CDATA[데이터 선정 : kaggle credit customer dataset (https://www.kaggle.com/arjunbhasin2013/ccdata)]]></summary></entry><entry><title type="html">정규화, 표준화 그리고 PCA</title><link href="http://localhost:4000/ds/pca/" rel="alternate" type="text/html" title="정규화, 표준화 그리고 PCA" /><published>2022-02-20T00:00:00+09:00</published><updated>2022-02-21T00:00:00+09:00</updated><id>http://localhost:4000/ds/pca</id><content type="html" xml:base="http://localhost:4000/ds/pca/"><![CDATA[<h2 id="정규화와-표준화">정규화와 표준화</h2>
<blockquote>
  <p>정규화 (normalization)</p>
</blockquote>

<p>정규화는 모든 값들을 0과 1사이의 값으로 단순하게 축소한다.<br />
예를 들어 0~100까지의 값중 35 는 0.35가 될 뿐이다. <br />
식 : x = (원래값 - 최댓값) / (최댓값 - 최솟값)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

df_scaled = scaler.fit_transform(df)
</code></pre></div></div>

<blockquote>
  <p>표준화 (standardization)</p>
</blockquote>

<p>표준화는 데이터를 0을 중심으로 양쪽으로 데이터를 분포시킨다.<br />
정확히는 0의 평균을 갖고, 1의 표준편차를 갖도록 변환하는 것.</p>

<p>식 : x = (원래값 - 평균) / 표준편차</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.preprocessing import StandardScaler
sclaer = StandardScaler()

df_scaled = scaler.fit_transform(df)
</code></pre></div></div>

<blockquote>
  <p>fit 과 fit transform 의 차이</p>
</blockquote>

<p>fit은 해당 데이터에 맞춤으로 모델(객체)을 설정해주는 것.<br />
fit_transform 은 fit함과 동시에 해당 데이터를 모델을 사용해서 변형해주어 return함.</p>

<h2 id="분산과-공분산">분산과 공분산</h2>

<blockquote>
  <p>분산 (variance)</p>
</blockquote>

<p>하나의 feature가 갖는 ‘평균으로 부터 퍼져있는 정도’ 이다.<br />
식 : Var(x) = E [(X-X평균)^2]</p>

<p>분산의 양의 제곱근이 표준편차(Standard Deviation)</p>

<blockquote>
  <p>공분산 (Covariance)</p>
</blockquote>

<p>두 feature가 갖는 공동 변화량이다. 직관적으로는 이해하기 힘들더라.. 그 의미를 파악하자면<br />
<strong>0보다크면 X가 증가할때 Y도 증가한다.(양의 상관관계)</strong><br />
<strong>0보 작으면 서로 음의 상관관계</strong><br />
식 : Cov(X,Y) = E[(X-X평균)(Y-Y평균)]</p>

<blockquote>
  <p>상관계수 (Correlation coefficient)</p>
</blockquote>

<p>공분산과 자연스럽게 이어지는데, 상관계수는 <strong>얼만큼</strong> 상관관계를 갖는지도 알려준다.</p>

<p>식 : Corr(X,Y) = Cov(X,Y) / (sd(X)*sd(Y))  (sd는 표준편차)</p>

<h2 id="pca">PCA</h2>
<p><strong>표준화or정규화 필수!!!!</strong><br />
PCA는 고 차원(feature 종류가 많을 때)의 데이터셋을 차원축소 하고자 할 때 사용한다.<br />
여기서 중요한건 PCA는 특정한 feature를 선택(selection)하는 것이 아니라<br />
모든 feature의 특징을 담아내는 feature로 추출(Extraction) 한다는 것이다.</p>

<p>어떻게 Extraction할 것이냐 !!
바로 <strong>축을 고르는 것</strong> 이다.</p>

<p>어떠한 축에 모든 feature들을 projection시켰을 때, ‘가장 그 정보들을 많이 담는다’면 그 축은 모든 feature의 특징을<br />
잘 담고 있는 축이 될 것이다.<br />
‘정보를 많이 담는다’는 것은 공분산이 가장 큰 것이다라고 이해했으며,<br />
그 축에 projection시킨 값들의 집합하나가 하나의 차원이 될 것이다.<br />
그리고 그 다음 축은 첫번째 축과 직교인 축으로 고르게 될 것이다.<br />
<img src="/assets/images/source_10.png" width="60%" height="60%" title="제목" alt="아무거나" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>features = df.loc[:,'bill_length_mm':'body_mass_g']
species = df['species']
</code></pre></div></div>
<p>↪️ df에서 ‘bill_length_mm’부터 ‘body_mass_g’ 까지의 feature의 데이터만 가져오고, ‘species’만 가져온다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
features = pd.DataFrame(scaler.fit_transform(features), columns=['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g'])
</code></pre></div></div>
<p>↪️ 표준화를 진행한다. (<strong>필수!!!!!</strong>)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import numpy as np
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
extracted_df = pd.DataFrame(pca.fit_transform(features), columns=['PC1', 'PC2'])
</code></pre></div></div>
<p>↪️ pca를 실행한 후 ‘PC1’, ‘PC2’로 저장된(자동으로 이름 이렇게 지음) 두 차원만 불러온다.<br />
두 차원으로 차원축소 성공 !
<br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄
</code></pre></div></div>

<p><a href="#" class="btn btn--primary align-right">맨 위로 이동하기</a></p>]]></content><author><name>옹달샘👱🏼‍♂️</name></author><category term="ds" /><summary type="html"><![CDATA[정규화와 표준화 정규화 (normalization)]]></summary></entry></feed>